{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJaM-35yxb8F",
        "outputId": "42b31e8e-c04f-4921-a31c-39c79a2d0ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PkgvaFRu-rD"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMmCQDIDtEKk"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "I6y5vBMAsBx7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report, precision_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VS49msUjYNh",
        "outputId": "6705d6c7-6d9b-4d08-c426-5fa40214efa1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZALYW7Z0tJvU"
      },
      "outputs": [],
      "source": [
        "## paths where datasets are located\n",
        "enron1_train_ham_path = \"//content//drive//MyDrive//project1_datasets//enron1_train//train//ham\"\n",
        "enron1_train_spam_path = \"//content//drive//MyDrive//project1_datasets//enron1_train//train//spam\"\n",
        "enron1_test_ham_path = \"//content//drive//MyDrive//project1_datasets//enron1_test//test//ham\"\n",
        "enron1_test_spam_path = \"//content//drive//MyDrive//project1_datasets//enron1_test//test//spam\"\n",
        "\n",
        "enron2_train_ham_path = \"//content//drive//MyDrive//project1_datasets//enron2_train//train//ham\"\n",
        "enron2_train_spam_path = \"//content//drive//MyDrive//project1_datasets//enron2_train//train//spam\"\n",
        "enron2_test_ham_path = \"//content//drive//MyDrive//project1_datasets//enron2_test//test//ham\"\n",
        "enron2_test_spam_path = \"//content//drive//MyDrive//project1_datasets//enron2_test//test//spam\"\n",
        "\n",
        "enron4_train_ham_path = \"//content//drive//MyDrive//project1_datasets//enron4_train//train//ham\"\n",
        "enron4_train_spam_path = \"//content//drive//MyDrive//project1_datasets//enron4_train//train//spam\"\n",
        "enron4_test_ham_path = \"//content//drive//MyDrive//project1_datasets//enron4_test//test//ham\"\n",
        "enron4_test_spam_path = \"//content//drive//MyDrive//project1_datasets//enron4_test//test//spam\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX611S6dtba4"
      },
      "source": [
        "## Creating the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmTgMjTltbAe",
        "outputId": "674dda21-dbab-498b-dc9f-89eac94f2fe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2925"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data = []\n",
        "\n",
        "def create_dataset(path):\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        for filename in filenames:\n",
        "            with open(path+\"//\"+filename, \"rb\") as f:\n",
        "                all_data.append([f.read(), path.split(\"//\")[-1]])\n",
        "\n",
        "paths = [enron1_train_ham_path, enron1_train_spam_path, enron1_test_ham_path, enron1_test_spam_path, enron2_train_ham_path, enron2_train_spam_path, enron2_test_ham_path, enron2_test_spam_path, enron4_train_ham_path, enron4_train_spam_path, enron4_test_ham_path, enron4_test_spam_path]\n",
        "\n",
        "for path in paths:\n",
        "    create_dataset(path)\n",
        "\n",
        "len(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5opri2mtiQC",
        "outputId": "63ff0b72-ec3e-47d5-9000-07ef4499aec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "319 131\n",
            "340 123\n",
            "133 402\n",
            "307 149\n",
            "348 130\n",
            "152 391\n"
          ]
        }
      ],
      "source": [
        "# creating each enron dataset\n",
        "def create_individual_dataset(path, dataset):\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        for filename in filenames:\n",
        "            with open(path+\"//\"+filename, \"rb\") as f:\n",
        "                dataset.append([f.read(), path.split(\"//\")[-1]])\n",
        "    return dataset\n",
        "\n",
        "\"\"\"For training\"\"\"\n",
        "enron1_train_ham_df = []\n",
        "enron1_train_ham_df = create_individual_dataset(enron1_train_ham_path, enron1_train_ham_df)\n",
        "enron1_train_spam_df = []\n",
        "enron1_train_spam_df = create_individual_dataset(enron1_train_spam_path, enron1_train_spam_df)\n",
        "\n",
        "print(len(enron1_train_ham_df), len(enron1_train_spam_df))\n",
        "\n",
        "enron2_train_ham_df = []\n",
        "enron2_train_ham_df = create_individual_dataset(enron2_train_ham_path, enron2_train_ham_df)\n",
        "enron2_train_spam_df = []\n",
        "enron2_train_spam_df = create_individual_dataset(enron2_train_spam_path, enron2_train_spam_df)\n",
        "\n",
        "print(len(enron2_train_ham_df), len(enron2_train_spam_df))\n",
        "\n",
        "enron4_train_ham_df = []\n",
        "enron4_train_ham_df = create_individual_dataset(enron4_train_ham_path, enron4_train_ham_df)\n",
        "enron4_train_spam_df = []\n",
        "enron4_train_spam_df = create_individual_dataset(enron4_train_spam_path, enron4_train_spam_df)\n",
        "\n",
        "print(len(enron4_train_ham_df), len(enron4_train_spam_df))\n",
        "\n",
        "\"\"\"For testing\"\"\"\n",
        "enron1_test_ham_df = []\n",
        "enron1_test_ham_df = create_individual_dataset(enron1_test_ham_path, enron1_test_ham_df)\n",
        "enron1_test_spam_df = []\n",
        "enron1_test_spam_df = create_individual_dataset(enron1_test_spam_path, enron1_test_spam_df)\n",
        "\n",
        "print(len(enron1_test_ham_df), len(enron1_test_spam_df))\n",
        "\n",
        "enron2_test_ham_df = []\n",
        "enron2_test_ham_df = create_individual_dataset(enron2_test_ham_path, enron2_test_ham_df)\n",
        "enron2_test_spam_df = []\n",
        "enron2_test_spam_df = create_individual_dataset(enron2_test_spam_path, enron2_test_spam_df)\n",
        "\n",
        "print(len(enron2_test_ham_df), len(enron2_test_spam_df))\n",
        "\n",
        "enron4_test_ham_df = []\n",
        "enron4_test_ham_df = create_individual_dataset(enron4_test_ham_path, enron4_test_ham_df)\n",
        "enron4_test_spam_df = []\n",
        "enron4_test_spam_df = create_individual_dataset(enron4_test_spam_path, enron4_test_spam_df)\n",
        "\n",
        "print(len(enron4_test_ham_df), len(enron4_test_spam_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IMYZGxyOuejA"
      },
      "outputs": [],
      "source": [
        "\"\"\"Converting string to byte string\"\"\"\n",
        "\n",
        "def convert_to_str(data):\n",
        "    converted_data = []\n",
        "    for item in data:\n",
        "        if isinstance(item[0], bytes):\n",
        "            # If the item is in bytes, decode it to a string\n",
        "            converted_data.append([item[0].decode('utf-8', errors='ignore'), item[1]])\n",
        "        else:\n",
        "            # If the item is already a string, just append it\n",
        "                 converted_data.append([item[0], item[1]])\n",
        "    return converted_data\n",
        "\n",
        "\n",
        "all_data = convert_to_str(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "A1XXWT8Lukij"
      },
      "outputs": [],
      "source": [
        "enron1_train_ham_df = convert_to_str(enron1_train_ham_df)\n",
        "enron1_train_spam_df = convert_to_str(enron1_train_spam_df)\n",
        "enron2_train_ham_df = convert_to_str(enron2_train_ham_df)\n",
        "enron2_train_spam_df = convert_to_str(enron2_train_spam_df)\n",
        "enron4_train_ham_df = convert_to_str(enron4_train_ham_df)\n",
        "enron4_train_spam_df = convert_to_str(enron4_train_spam_df)\n",
        "\n",
        "enron1_test_ham_df = convert_to_str(enron1_test_ham_df)\n",
        "enron1_test_spam_df = convert_to_str(enron1_test_spam_df)\n",
        "enron2_test_ham_df = convert_to_str(enron2_test_ham_df)\n",
        "enron2_test_spam_df = convert_to_str(enron2_test_spam_df)\n",
        "enron4_test_ham_df = convert_to_str(enron4_test_ham_df)\n",
        "enron4_test_spam_df = convert_to_str(enron4_test_spam_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC_Yss6HumPj",
        "outputId": "907b6c8b-a6e3-43d9-db29-d69fda1ebfc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "450\n",
            "463\n",
            "535\n",
            "456\n",
            "478\n",
            "543\n"
          ]
        }
      ],
      "source": [
        "enron1_train_spam_df.extend(enron1_train_ham_df)\n",
        "enron1_train = enron1_train_spam_df\n",
        "print(len(enron1_train))\n",
        "\n",
        "enron2_train_spam_df.extend(enron2_train_ham_df)\n",
        "enron2_train = enron2_train_spam_df\n",
        "print(len(enron2_train))\n",
        "\n",
        "enron4_train_spam_df.extend(enron4_train_ham_df)\n",
        "enron4_train = enron4_train_spam_df\n",
        "print(len(enron4_train))\n",
        "\n",
        "enron1_test_spam_df.extend(enron1_test_ham_df)\n",
        "enron1_test = enron1_test_spam_df\n",
        "print(len(enron1_test))\n",
        "\n",
        "enron2_test_spam_df.extend(enron2_test_ham_df)\n",
        "enron2_test = enron2_test_spam_df\n",
        "print(len(enron2_test))\n",
        "\n",
        "enron4_test_spam_df.extend(enron4_test_ham_df)\n",
        "enron4_test = enron4_test_spam_df\n",
        "print(len(enron4_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBZFwRrkux8C"
      },
      "source": [
        "## Convert list to Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXN-9jJ-uv46",
        "outputId": "082b4c9f-bf2c-4796-f582-daa78c82468b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2925, 2)\n",
            "(450, 2)\n",
            "(463, 2)\n",
            "(535, 2)\n",
            "(456, 2)\n",
            "(478, 2)\n",
            "(543, 2)\n"
          ]
        }
      ],
      "source": [
        "def convert_to_df(data):\n",
        "    df = pd.DataFrame(data, columns=['Email', 'Type'])\n",
        "    print(df.shape)\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "all_data_df = convert_to_df(all_data)\n",
        "\n",
        "enron1_train_df = convert_to_df(enron1_train)\n",
        "enron2_train_df = convert_to_df(enron2_train)\n",
        "enron4_train_df = convert_to_df(enron4_train)\n",
        "\n",
        "enron1_test_df = convert_to_df(enron1_test)\n",
        "enron2_test_df = convert_to_df(enron2_test)\n",
        "enron4_test_df = convert_to_df(enron4_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEV3XJjFidh6",
        "outputId": "d2d7a99b-b45a-45e8-bfef-ea67f4008428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(450, 2)\n",
            "(463, 2)\n",
            "(535, 2)\n",
            "(456, 2)\n",
            "(478, 2)\n",
            "(543, 2)\n"
          ]
        }
      ],
      "source": [
        "copy_of_enron1_train_df = convert_to_df(enron1_train)\n",
        "copy_of_enron2_train_df = convert_to_df(enron2_train)\n",
        "copy_of_enron4_train_df = convert_to_df(enron4_train)\n",
        "\n",
        "copy_of_enron1_test_df = convert_to_df(enron1_test)\n",
        "copy_of_enron2_test_df = convert_to_df(enron2_test)\n",
        "copy_of_enron4_test_df = convert_to_df(enron4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9kyv7l1u3jD"
      },
      "source": [
        "## Preprocessing the data\n",
        "\n",
        "For preprocessing the data, I have performed the following operations -\n",
        "\n",
        "- Converting text to lower case\n",
        "\n",
        "- Rmoving punctuations\n",
        "\n",
        "- Creating word tokens\n",
        "\n",
        "- Removing stop words\n",
        "\n",
        "- Lemmatization\n",
        "\n",
        "- Removing non alphabetic character\n",
        "\n",
        "**For this project I have used the Natural Language Toolkit (NLTK) library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4m0WcXYJu1FY"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    # conver to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # remove punctuations\n",
        "    text = text.translate(str.maketrans('','', string.punctuation))\n",
        "\n",
        "    # tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # stop word removal\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # lemmatization\n",
        "    lemma = WordNetLemmatizer()\n",
        "    filtered = [lemma.lemmatize(word) for word in filtered]\n",
        "\n",
        "    # remove non-alphabetic characters\n",
        "    filtered = [word for word in filtered if word.isalpha()]\n",
        "\n",
        "    return filtered\n",
        "\n",
        "## Applying the function to Email column\n",
        "all_data_df['Email_tok'] = all_data_df['Email'].apply(preprocess)\n",
        "\n",
        "enron1_train_df['Email_tok'] = enron1_train_df['Email'].apply(preprocess)\n",
        "enron2_train_df['Email_tok'] = enron2_train_df['Email'].apply(preprocess)\n",
        "enron4_train_df['Email_tok'] = enron4_train_df['Email'].apply(preprocess)\n",
        "\n",
        "enron1_test_df['Email_tok'] = enron1_test_df['Email'].apply(preprocess)\n",
        "enron2_test_df['Email_tok'] = enron2_test_df['Email'].apply(preprocess)\n",
        "enron4_test_df['Email_tok'] = enron4_test_df['Email'].apply(preprocess)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1FyyTDVSu8Dr"
      },
      "outputs": [],
      "source": [
        "all_data_df['Email_str'] = all_data_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "enron1_train_df['Email_str'] = enron1_train_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "enron2_train_df['Email_str'] = enron2_train_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "enron4_train_df['Email_str'] = enron4_train_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "enron1_test_df['Email_str'] = enron1_test_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "enron2_test_df['Email_str'] = enron2_test_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "enron4_test_df['Email_str'] = enron4_test_df['Email_tok'].apply(lambda x: ' '.join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "37FkcZOAvJkU",
        "outputId": "3a54a3f8-efe6-47bc-b1c5-1d6699a20eeb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"enron1_train_df\",\n  \"rows\": 450,\n  \"fields\": [\n    {\n      \"column\": \"Email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 448,\n        \"samples\": [\n          \"Subject: august wellhead production estimate\\r\\ndaren ,\\r\\nhere it is . i thought vance had already given this to you .\\r\\nbob\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by robert cotten / hou / ect on 07 / 25 / 2000 01 : 25\\r\\npm - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\nvance l taylor\\r\\n07 / 24 / 2000 09 : 43 am\\r\\nto : robert cotten / hou / ect @ ect\\r\\ncc : melissa graves / hou / ect @ ect\\r\\nsubject : august wellhead production estimate\\r\\nbob ,\\r\\nplease see the attached file estimating wellhead production for the month of\\r\\naugust . please be advised that this is a preliminary estimate as to this\\r\\ndate , we have received only a few noms for august . i will update you with\\r\\nany revisions as they occur .\\r\\nthanks ,\\r\\nvlt\\r\\nx 3 - 6353\",\n          \"Subject: lose it\\r\\nos effetiveeight os aaiabe withoutrescription\\r\\nlearn about it here\\r\\nunlist me\\r\\n\",\n          \"Subject: painn killers weiight loss no docctor\\r\\nyour place to ggo too for all ur prreeiscrlpt 10 n pi | | s ,\\r\\nno doxxtctorr neeedeed .\\r\\npaaiixnnninxxn kiiiiilllerxxs\\r\\nhttp : / / gettmeeeeofff - nowww . com / goto /\\r\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Email_tok\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Email_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 442,\n        \"samples\": [\n          \"subject cheat date l f lot hot mommy need coock meet married woman one dollar fee chat room rockin http www datemomsnow biz emms preference control php browse counterfeit enclave famine prerequisite weyerhauser leach birch edgerton cheesecloth indefatigable abyssinia cattleman hurwitz remunerate thule culprit structural discrepant cacophonist epsilon epidemiology kirchoff tuesday cretin johannes bereave stipple\",\n          \"subject hr performance objective binder good morning afternoon today everyone received binder placed mail slot others hand delivered receive binder please email call one delivered thank octavia x\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "enron1_train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b9bbadc0-98ad-4dfd-a4bb-aaa5b8cfacbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email</th>\n",
              "      <th>Type</th>\n",
              "      <th>Email_tok</th>\n",
              "      <th>Email_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: re : formosa meter # : 1000\\r\\nthe de...</td>\n",
              "      <td>ham</td>\n",
              "      <td>[subject, formosa, meter, deal, continue, mont...</td>\n",
              "      <td>subject formosa meter deal continue month past...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: dec 2000 prod : panther pipeline dema...</td>\n",
              "      <td>ham</td>\n",
              "      <td>[subject, dec, prod, panther, pipeline, demand...</td>\n",
              "      <td>subject dec prod panther pipeline demand charg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: mobil beaumont - may 2001\\r\\ndaren ,\\...</td>\n",
              "      <td>ham</td>\n",
              "      <td>[subject, mobil, beaumont, may, daren, want, c...</td>\n",
              "      <td>subject mobil beaumont may daren want confirm ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: aol instant messenger reconfirmation\\...</td>\n",
              "      <td>ham</td>\n",
              "      <td>[subject, aol, instant, messenger, reconfirmat...</td>\n",
              "      <td>subject aol instant messenger reconfirmation t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: credit watch list - - week of 11 / 5 ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>[subject, credit, watch, list, week, attached,...</td>\n",
              "      <td>subject credit watch list week attached revise...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>Subject: correction to 4 / 4 &amp; 4 / 5 nominatio...</td>\n",
              "      <td>ham</td>\n",
              "      <td>[subject, correction, nomination, eastrans, re...</td>\n",
              "      <td>subject correction nomination eastrans result ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>Subject: re : noms / actual flow for 4 / 01 / ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>[subject, noms, actual, flow, agree, april, ei...</td>\n",
              "      <td>subject noms actual flow agree april eileen po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>Subject: hpl nom for march 28 , 2000\\r\\n( see ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>[subject, hpl, nom, march, see, attached, file...</td>\n",
              "      <td>subject hpl nom march see attached file hplo x...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>Subject: playful asian cutie !\\r\\nthis damn se...</td>\n",
              "      <td>spam</td>\n",
              "      <td>[subject, playful, asian, cutie, damn, sexy, c...</td>\n",
              "      <td>subject playful asian cutie damn sexy cutie wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>Subject: killam oil company , ltd . , meters 0...</td>\n",
              "      <td>ham</td>\n",
              "      <td>[subject, killam, oil, company, ltd, meter, br...</td>\n",
              "      <td>subject killam oil company ltd meter bruni hug...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>450 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9bbadc0-98ad-4dfd-a4bb-aaa5b8cfacbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9bbadc0-98ad-4dfd-a4bb-aaa5b8cfacbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9bbadc0-98ad-4dfd-a4bb-aaa5b8cfacbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-24f6309d-4ad5-43e9-b070-861a1f2ac420\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24f6309d-4ad5-43e9-b070-861a1f2ac420')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-24f6309d-4ad5-43e9-b070-861a1f2ac420 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ddfa1d17-52a9-4faf-a018-f68ab5c78ab8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('enron1_train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ddfa1d17-52a9-4faf-a018-f68ab5c78ab8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('enron1_train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 Email  Type  \\\n",
              "0    Subject: re : formosa meter # : 1000\\r\\nthe de...   ham   \n",
              "1    Subject: dec 2000 prod : panther pipeline dema...   ham   \n",
              "2    Subject: mobil beaumont - may 2001\\r\\ndaren ,\\...   ham   \n",
              "3    Subject: aol instant messenger reconfirmation\\...   ham   \n",
              "4    Subject: credit watch list - - week of 11 / 5 ...   ham   \n",
              "..                                                 ...   ...   \n",
              "445  Subject: correction to 4 / 4 & 4 / 5 nominatio...   ham   \n",
              "446  Subject: re : noms / actual flow for 4 / 01 / ...   ham   \n",
              "447  Subject: hpl nom for march 28 , 2000\\r\\n( see ...   ham   \n",
              "448  Subject: playful asian cutie !\\r\\nthis damn se...  spam   \n",
              "449  Subject: killam oil company , ltd . , meters 0...   ham   \n",
              "\n",
              "                                             Email_tok  \\\n",
              "0    [subject, formosa, meter, deal, continue, mont...   \n",
              "1    [subject, dec, prod, panther, pipeline, demand...   \n",
              "2    [subject, mobil, beaumont, may, daren, want, c...   \n",
              "3    [subject, aol, instant, messenger, reconfirmat...   \n",
              "4    [subject, credit, watch, list, week, attached,...   \n",
              "..                                                 ...   \n",
              "445  [subject, correction, nomination, eastrans, re...   \n",
              "446  [subject, noms, actual, flow, agree, april, ei...   \n",
              "447  [subject, hpl, nom, march, see, attached, file...   \n",
              "448  [subject, playful, asian, cutie, damn, sexy, c...   \n",
              "449  [subject, killam, oil, company, ltd, meter, br...   \n",
              "\n",
              "                                             Email_str  \n",
              "0    subject formosa meter deal continue month past...  \n",
              "1    subject dec prod panther pipeline demand charg...  \n",
              "2    subject mobil beaumont may daren want confirm ...  \n",
              "3    subject aol instant messenger reconfirmation t...  \n",
              "4    subject credit watch list week attached revise...  \n",
              "..                                                 ...  \n",
              "445  subject correction nomination eastrans result ...  \n",
              "446  subject noms actual flow agree april eileen po...  \n",
              "447  subject hpl nom march see attached file hplo x...  \n",
              "448  subject playful asian cutie damn sexy cutie wa...  \n",
              "449  subject killam oil company ltd meter bruni hug...  \n",
              "\n",
              "[450 rows x 4 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enron1_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUdbkfbbwhtE"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy = {}\n",
        "all_results_recall = {}\n",
        "all_results_f1 = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0VaGCC-vWf1"
      },
      "source": [
        "## Multinomial Naive Bayes using Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZeL3JjKvZxU"
      },
      "source": [
        "### Scikit-learn approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdL2OoxfvKE9",
        "outputId": "8c117f5f-5896-4dfa-9d92-21523bdfed97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron1\n",
            "accuracy - 0.9298245614035088\n",
            "recall - 0.8657718120805369\n",
            "f1 score - 0.8896551724137931\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.94      0.96      0.95       307\n",
            "        spam       0.91      0.87      0.89       149\n",
            "\n",
            "    accuracy                           0.93       456\n",
            "   macro avg       0.93      0.91      0.92       456\n",
            "weighted avg       0.93      0.93      0.93       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "enron2\n",
            "accuracy - 0.9456066945606695\n",
            "recall - 0.8769230769230769\n",
            "f1 score - 0.8976377952755904\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.97      0.96       348\n",
            "        spam       0.92      0.88      0.90       130\n",
            "\n",
            "    accuracy                           0.95       478\n",
            "   macro avg       0.94      0.92      0.93       478\n",
            "weighted avg       0.95      0.95      0.95       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "enron4\n",
            "accuracy - 0.9742173112338858\n",
            "recall - 0.9948849104859335\n",
            "f1 score - 0.9823232323232323\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.92      0.95       152\n",
            "        spam       0.97      0.99      0.98       391\n",
            "\n",
            "    accuracy                           0.97       543\n",
            "   macro avg       0.98      0.96      0.97       543\n",
            "weighted avg       0.97      0.97      0.97       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "{'sklearn_bow_enron1': 0.9298245614035088, 'sklearn_bow_enron2': 0.9456066945606695, 'sklearn_bow_enron4': 0.9742173112338858, 'step_by_step_bow_enron1': 0.9742173112338858, 'step_by_step_bow_enron2': 0.9742173112338858, 'step_by_step_bow_enron4': 0.9742173112338858}\n",
            "{'sklearn_bow_enron1': 0.8657718120805369, 'sklearn_bow_enron2': 0.8769230769230769, 'sklearn_bow_enron4': 0.9948849104859335, 'step_by_step_bow_enron1': 0.87248322147651, 'step_by_step_bow_enron2': 0.8769230769230769, 'step_by_step_bow_enron4': 0.9948849104859335}\n",
            "{'sklearn_bow_enron1': 0.8896551724137931, 'sklearn_bow_enron2': 0.8976377952755904, 'sklearn_bow_enron4': 0.9823232323232323, 'step_by_step_bow_enron1': 0.8934707903780068, 'step_by_step_bow_enron2': 0.8941176470588236, 'step_by_step_bow_enron4': 0.9810844892812105}\n"
          ]
        }
      ],
      "source": [
        "def predict_type(X_train, X_test, name):\n",
        "    y_train = X_train['Type']\n",
        "    y_test = X_test['Type']\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train['Email_str'])\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "\n",
        "    model = MultinomialNB(alpha=1.0)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred, pos_label='spam')\n",
        "    f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "    return accuracy, recall, f1\n",
        "\n",
        "\n",
        "accuracy, recall, f1 = predict_type(enron1_train_df, enron1_test_df, 'enron1')\n",
        "all_results_accuracy['sklearn_bow_enron1'] = accuracy\n",
        "all_results_recall['sklearn_bow_enron1'] = recall\n",
        "all_results_f1['sklearn_bow_enron1'] = f1\n",
        "\n",
        "accuracy, recall, f1 = predict_type(enron2_train_df, enron2_test_df, 'enron2')\n",
        "all_results_accuracy['sklearn_bow_enron2'] = accuracy\n",
        "all_results_recall['sklearn_bow_enron2'] = recall\n",
        "all_results_f1['sklearn_bow_enron2'] = f1\n",
        "\n",
        "accuracy, recall, f1 = predict_type(enron4_train_df, enron4_test_df, 'enron4')\n",
        "all_results_accuracy['sklearn_bow_enron4'] = accuracy\n",
        "all_results_recall['sklearn_bow_enron4'] = recall\n",
        "all_results_f1['sklearn_bow_enron4'] = f1\n",
        "\n",
        "print(all_results_accuracy)\n",
        "print(all_results_recall)\n",
        "print(all_results_f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3kXSwpqw3Vz"
      },
      "source": [
        "### Step by step approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJz79JdDvvH_",
        "outputId": "bbddd2b5-7a68-4a36-b5c4-9a8fb080ffc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron1\n",
            "Accuracy = 93.2017543859649%\n",
            "Recall =  0.87248322147651\n",
            "F1 =  0.8934707903780068\n",
            "-----------------------------------------------------------\n",
            "enron2\n",
            "Accuracy = 94.35146443514645%\n",
            "Recall =  0.8769230769230769\n",
            "F1 =  0.8941176470588236\n",
            "-----------------------------------------------------------\n",
            "enron4\n",
            "Accuracy = 97.23756906077348%\n",
            "Recall =  0.9948849104859335\n",
            "F1 =  0.9810844892812105\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to train Multinomial Naive Bayes\n",
        "def train_multinomial_naive_bayes(df):\n",
        "    cond_prob_ham = {}\n",
        "    cond_prob_spam = {}\n",
        "\n",
        "    \"\"\"Extracting vocabulary\"\"\"\n",
        "    vocabulary = set()\n",
        "    for email in df['Email_str']:  # Iterate over each email\n",
        "        tokens = email.split()  # Split each email into words\n",
        "        vocabulary.update(tokens)  # Add tokens to the vocabulary\n",
        "    vocabulary = list(vocabulary)\n",
        "\n",
        "    \"\"\"Counting the number of emails in each class\"\"\"\n",
        "    ham_docs = df[df['Type'] == 'ham'].shape[0]\n",
        "    spam_docs = df[df['Type'] == 'spam'].shape[0]\n",
        "    total_docs = df.shape[0]\n",
        "\n",
        "    \"\"\"Join the text of emails belonging to the same class\"\"\"\n",
        "    text_ham = \" \".join(df[df['Type'] == 'ham']['Email_str'].astype(str))\n",
        "    text_spam = \" \".join(df[df['Type'] == 'spam']['Email_str'].astype(str))\n",
        "\n",
        "    \"\"\"Calculating priors\"\"\"\n",
        "    prior_ham = ham_docs / total_docs\n",
        "    prior_spam = spam_docs / total_docs\n",
        "\n",
        "    \"\"\"Count tokens in ham and spam classes\"\"\"\n",
        "    tokens_in_ham = sum(text_ham.split().count(term) for term in vocabulary)\n",
        "    tokens_in_spam = sum(text_spam.split().count(term) for term in vocabulary)\n",
        "\n",
        "    \"\"\"Calculating conditional probabilities\"\"\"\n",
        "    for term in vocabulary:\n",
        "        tct_ham = text_ham.split().count(term)\n",
        "        cond_prob_ham[term] = (tct_ham + 1.0) / (tokens_in_ham + len(vocabulary))\n",
        "\n",
        "        tct_spam = text_spam.split().count(term)\n",
        "        cond_prob_spam[term] = (tct_spam + 1.0) / (tokens_in_spam + len(vocabulary))\n",
        "\n",
        "    return vocabulary, cond_prob_spam, cond_prob_ham, prior_ham, prior_spam\n",
        "\n",
        "# Function to classify emails using the trained model\n",
        "def apply_mnb(prior_ham, prior_spam, vocabulary, email, cond_prob_ham, cond_prob_spam):\n",
        "    tokens = email.split()\n",
        "    scores = {'ham': np.log(prior_ham), 'spam': np.log(prior_spam)}  # Log priors\n",
        "\n",
        "    for token in tokens:\n",
        "        if token in cond_prob_ham:\n",
        "            scores['ham'] += np.log(cond_prob_ham[token])\n",
        "        else:\n",
        "            scores['ham'] += np.log(1 / (sum(cond_prob_ham.get(t, 0) for t in vocabulary) + len(vocabulary)))\n",
        "\n",
        "        if token in cond_prob_spam:\n",
        "            scores['spam'] += np.log(cond_prob_spam[token])\n",
        "        else:\n",
        "            scores['spam'] += np.log(1 / (sum(cond_prob_spam.get(t, 0) for t in vocabulary) + len(vocabulary)))\n",
        "\n",
        "    return max(scores, key=scores.get)\n",
        "\n",
        "# Function to classify and evaluate test documents\n",
        "def funct(train_df, test_df, name):\n",
        "    # Train the Multinomial Naive Bayes model\n",
        "    vocabulary, cond_prob_spam, cond_prob_ham, prior_ham, prior_spam = train_multinomial_naive_bayes(train_df)\n",
        "\n",
        "    # Classify test documents\n",
        "    results = []\n",
        "    for email in test_df['Email_str']:\n",
        "        results.append(apply_mnb(prior_ham, prior_spam, vocabulary, email, cond_prob_ham, cond_prob_spam))\n",
        "\n",
        "    # Evaluate the predictions\n",
        "    correct_predictions = sum(pred == true for pred, true in zip(results, test_df['Type']))\n",
        "    accuracy_score = correct_predictions / len(results)\n",
        "    recall = recall_score(test_df['Type'], results, pos_label='spam')\n",
        "    f1 = f1_score(test_df['Type'], results, pos_label='spam')\n",
        "\n",
        "    # Print the results\n",
        "    print(name)\n",
        "    print(f\"Accuracy = {accuracy_score * 100}%\")\n",
        "    print(\"Recall = \", recall)\n",
        "    print(\"F1 = \", f1)\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    return accuracy, recall, f1\n",
        "\n",
        "# Example usage with datasets\n",
        "accuracy_e1, recall_e1, f1_e1 = funct(enron1_train_df, enron1_test_df, 'enron1')\n",
        "accuracy_e2, recall_e2, f1_e2 = funct(enron2_train_df, enron2_test_df, 'enron2')\n",
        "accuracy_e4, recall_e4, f1_e4 = funct(enron4_train_df, enron4_test_df, 'enron4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni8fP6DwycUZ"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy['step_by_step_bow_enron1'] = accuracy_e1\n",
        "all_results_accuracy['step_by_step_bow_enron2'] = accuracy_e2\n",
        "all_results_accuracy['step_by_step_bow_enron4'] = accuracy_e4\n",
        "\n",
        "all_results_recall['step_by_step_bow_enron1'] = recall_e1\n",
        "all_results_recall['step_by_step_bow_enron2'] = recall_e2\n",
        "all_results_recall['step_by_step_bow_enron4'] = recall_e4\n",
        "\n",
        "all_results_f1['step_by_step_bow_enron1'] = f1_e1\n",
        "all_results_f1['step_by_step_bow_enron2'] = f1_e2\n",
        "all_results_f1['step_by_step_bow_enron4'] = f1_e4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I2YItWK0jCx",
        "outputId": "68fb8dd3-e4fe-44c6-f9ca-6f3d49540f3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sklearn_bow_enron1': 0.9298245614035088,\n",
              " 'sklearn_bow_enron2': 0.9456066945606695,\n",
              " 'sklearn_bow_enron4': 0.9742173112338858,\n",
              " 'step_by_step_bow_enron1': 0.9742173112338858,\n",
              " 'step_by_step_bow_enron2': 0.9742173112338858,\n",
              " 'step_by_step_bow_enron4': 0.9742173112338858}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_results_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JskH97IB08Ar"
      },
      "source": [
        "## Bernoulli Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqvZP4sX0--L"
      },
      "source": [
        "### Scikit learn approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef_azcU603Gr",
        "outputId": "394ece78-1bb8-441f-c62d-7fd25b593f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron1\n",
            "accuracy - 0.7302631578947368\n",
            "recall - 0.2080536912751678\n",
            "f1 score - 0.3351351351351351\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.72      0.98      0.83       307\n",
            "        spam       0.86      0.21      0.34       149\n",
            "\n",
            "    accuracy                           0.73       456\n",
            "   macro avg       0.79      0.60      0.58       456\n",
            "weighted avg       0.77      0.73      0.67       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "enron2\n",
            "accuracy - 0.7782426778242678\n",
            "recall - 0.2076923076923077\n",
            "f1 score - 0.3375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.77      0.99      0.87       348\n",
            "        spam       0.90      0.21      0.34       130\n",
            "\n",
            "    accuracy                           0.78       478\n",
            "   macro avg       0.84      0.60      0.60       478\n",
            "weighted avg       0.81      0.78      0.72       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "enron4\n",
            "accuracy - 0.9171270718232044\n",
            "recall - 1.0\n",
            "f1 score - 0.9455864570737605\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.70      0.83       152\n",
            "        spam       0.90      1.00      0.95       391\n",
            "\n",
            "    accuracy                           0.92       543\n",
            "   macro avg       0.95      0.85      0.89       543\n",
            "weighted avg       0.93      0.92      0.91       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def predict_type(X_train, X_test, name):\n",
        "    y_train = X_train['Type']\n",
        "\n",
        "    vectorizer = CountVectorizer(binary=True, stop_words=None)  # Ensure not filtering out all words\n",
        "\n",
        "    X_train_text = vectorizer.fit_transform(X_train['Email_str'])\n",
        "\n",
        "    model = BernoulliNB(alpha=1.0)\n",
        "    model.fit(X_train_text, y_train)\n",
        "\n",
        "    y_test = X_test['Type']\n",
        "    X_test_text = vectorizer.transform(X_test['Email_str'])\n",
        "\n",
        "    y_pred = model.predict(X_test_text)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "    return accuracy, recall, f1\n",
        "\n",
        "# Example usage with your dataframes\n",
        "sklearn_bern_acc_e1, sklearn_bern_recall_e1, sklearn_bern_f1_e1 = predict_type(enron1_train_df, enron1_test_df, 'enron1')\n",
        "sklearn_bern_acc_e2, sklearn_bern_recall_e2, sklearn_bern_f1_e2 = predict_type(enron2_train_df, enron2_test_df, 'enron2')\n",
        "sklearn_bern_acc_e4, sklearn_bern_recall_e4, sklearn_bern_f1_e4 = predict_type(enron4_train_df, enron4_test_df, 'enron4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R5igZtB1wGa"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy['sklearn_bern_enron1'] = sklearn_bern_acc_e1\n",
        "all_results_accuracy['sklearn_bern_enron2'] = sklearn_bern_acc_e2\n",
        "all_results_accuracy['sklearn_bern_enron4'] = sklearn_bern_acc_e4\n",
        "\n",
        "all_results_recall['sklearn_bern_enron1'] = sklearn_bern_recall_e1\n",
        "all_results_recall['sklearn_bern_enron2'] = sklearn_bern_recall_e2\n",
        "all_results_recall['sklearn_bern_enron4'] = sklearn_bern_recall_e4\n",
        "\n",
        "all_results_f1['sklearn_bern_enron1'] = sklearn_bern_f1_e1\n",
        "all_results_f1['sklearn_bern_enron2'] = sklearn_bern_f1_e2\n",
        "all_results_f1['sklearn_bern_enron4'] = sklearn_bern_f1_e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EowYDDp3TXA"
      },
      "source": [
        "### Step by step approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpBdvUQz19DM",
        "outputId": "3f0c01d0-868f-4192-e654-326042fbc1ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron1\n",
            "Accuracy = 73.02631578947368%\n",
            "Recall =  0.2080536912751678\n",
            "F1 =  0.3351351351351351\n",
            "-----------------------------------------------------------\n",
            "enron2\n",
            "Accuracy = 77.82426778242679%\n",
            "Recall =  0.2076923076923077\n",
            "F1 =  0.3375\n",
            "-----------------------------------------------------------\n",
            "enron4\n",
            "Accuracy = 91.71270718232044%\n",
            "Recall =  1.0\n",
            "F1 =  0.9455864570737605\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "\n",
        "# Function to train Bernoulli Naive Bayes\n",
        "def train_bernoulli_naive_bayes(df):\n",
        "    cond_prob_ham = {}\n",
        "    cond_prob_spam = {}\n",
        "\n",
        "    \"\"\"Extracting vocabulary\"\"\"\n",
        "    vocabulary = set()\n",
        "    for email in df['Email_str']:  # Iterate over each email\n",
        "        tokens = email.split()  # Split each email into words\n",
        "        vocabulary.update(tokens)  # Add tokens to the vocabulary\n",
        "    vocabulary = list(vocabulary)\n",
        "\n",
        "    \"\"\"Counting the number of emails in each class\"\"\"\n",
        "    ham_docs = df[df['Type'] == 'ham'].shape[0]\n",
        "    spam_docs = df[df['Type'] == 'spam'].shape[0]\n",
        "    total_docs = df.shape[0]\n",
        "\n",
        "    \"\"\"Join the text of emails belonging to the same class\"\"\"\n",
        "    ham_emails = df[df['Type'] == 'ham']['Email_str'].astype(str)\n",
        "    spam_emails = df[df['Type'] == 'spam']['Email_str'].astype(str)\n",
        "\n",
        "    \"\"\"Calculating priors\"\"\"\n",
        "    prior_ham = ham_docs / total_docs\n",
        "    prior_spam = spam_docs / total_docs\n",
        "\n",
        "    \"\"\"Calculating conditional probabilities (Bernoulli approach)\"\"\"\n",
        "    for term in vocabulary:\n",
        "        # For ham class: P(term|ham)\n",
        "        ham_with_term = sum(1 for email in ham_emails if term in email.split())\n",
        "        cond_prob_ham[term] = (ham_with_term + 1.0) / (ham_docs + 2.0)  # Laplace smoothing\n",
        "\n",
        "        # For spam class: P(term|spam)\n",
        "        spam_with_term = sum(1 for email in spam_emails if term in email.split())\n",
        "        cond_prob_spam[term] = (spam_with_term + 1.0) / (spam_docs + 2.0)  # Laplace smoothing\n",
        "\n",
        "    return vocabulary, cond_prob_spam, cond_prob_ham, prior_ham, prior_spam\n",
        "\n",
        "# Function to classify emails using the trained Bernoulli Naive Bayes model\n",
        "def apply_bnb(prior_ham, prior_spam, vocabulary, email, cond_prob_ham, cond_prob_spam):\n",
        "    tokens = set(email.split())  # Consider unique tokens for Bernoulli\n",
        "    scores = {'ham': np.log(prior_ham), 'spam': np.log(prior_spam)}  # Log priors\n",
        "\n",
        "    for term in vocabulary:\n",
        "        if term in tokens:\n",
        "            scores['ham'] += np.log(cond_prob_ham[term])\n",
        "            scores['spam'] += np.log(cond_prob_spam[term])\n",
        "        else:\n",
        "            scores['ham'] += np.log(1 - cond_prob_ham[term])\n",
        "            scores['spam'] += np.log(1 - cond_prob_spam[term])\n",
        "\n",
        "    return max(scores, key=scores.get)\n",
        "\n",
        "# Function to classify and evaluate test documents\n",
        "def funct(train_df, test_df, name):\n",
        "    # Train the Bernoulli Naive Bayes model\n",
        "    vocabulary, cond_prob_spam, cond_prob_ham, prior_ham, prior_spam = train_bernoulli_naive_bayes(train_df)\n",
        "\n",
        "    # Classify test documents\n",
        "    results = []\n",
        "    for email in test_df['Email_str']:\n",
        "        results.append(apply_bnb(prior_ham, prior_spam, vocabulary, email, cond_prob_ham, cond_prob_spam))\n",
        "\n",
        "    # Evaluate the predictions\n",
        "    correct_predictions = sum(pred == true for pred, true in zip(results, test_df['Type']))\n",
        "    accuracy_score = correct_predictions / len(results)\n",
        "    recall = recall_score(test_df['Type'], results, pos_label='spam')\n",
        "    f1 = f1_score(test_df['Type'], results, pos_label='spam')\n",
        "\n",
        "    # Print the results\n",
        "    print(name)\n",
        "    print(f\"Accuracy = {accuracy_score * 100}%\")\n",
        "    print(\"Recall = \", recall)\n",
        "    print(\"F1 = \", f1)\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    return accuracy_score, recall, f1\n",
        "\n",
        "# Example usage with datasets\n",
        "accuracy_e1, recall_e1, f1_e1 = funct(enron1_train_df, enron1_test_df, 'enron1')\n",
        "accuracy_e2, recall_e2, f1_e2 = funct(enron2_train_df, enron2_test_df, 'enron2')\n",
        "accuracy_e4, recall_e4, f1_e4 = funct(enron4_train_df, enron4_test_df, 'enron4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhiuaTUV3Xsz"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy['step_by_step_bern_enron1'] = accuracy_e1\n",
        "all_results_accuracy['step_by_step_bern_enron2'] = accuracy_e2\n",
        "all_results_accuracy['step_by_step_bern_enron4'] = accuracy_e4\n",
        "\n",
        "all_results_f1['step_by_step_bern_enron1'] = f1_e1\n",
        "all_results_f1['step_by_step_bern_enron2'] = f1_e2\n",
        "all_results_f1['step_by_step_bern_enron4'] = f1_e4\n",
        "\n",
        "all_results_recall['step_by_step_bern_enron1'] = recall_e1\n",
        "all_results_recall['step_by_step_bern_enron2'] = recall_e2\n",
        "all_results_recall['step_by_step_bern_enron4'] = recall_e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FHHjHSkA8eS"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vhmHKLUBDWd"
      },
      "source": [
        "### Scikit learn approach BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmY9T6aj4cDx",
        "outputId": "b1ca5e35-c8d8-403a-8478-3ac8d2b186cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron1\n",
            "accuracy - 0.9517543859649122\n",
            "recall - 0.959731543624161\n",
            "f1 score - 0.9285714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.95      0.96       307\n",
            "        spam       0.90      0.96      0.93       149\n",
            "\n",
            "    accuracy                           0.95       456\n",
            "   macro avg       0.94      0.95      0.95       456\n",
            "weighted avg       0.95      0.95      0.95       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "enron2\n",
            "accuracy - 0.9539748953974896\n",
            "recall - 0.9076923076923077\n",
            "f1 score - 0.9147286821705427\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.97      0.97       348\n",
            "        spam       0.92      0.91      0.91       130\n",
            "\n",
            "    accuracy                           0.95       478\n",
            "   macro avg       0.94      0.94      0.94       478\n",
            "weighted avg       0.95      0.95      0.95       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "enron4\n",
            "accuracy - 0.9521178637200737\n",
            "recall - 0.9974424552429667\n",
            "f1 score - 0.9677419354838709\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.84      0.91       152\n",
            "        spam       0.94      1.00      0.97       391\n",
            "\n",
            "    accuracy                           0.95       543\n",
            "   macro avg       0.97      0.92      0.94       543\n",
            "weighted avg       0.95      0.95      0.95       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def predict_type(X_train, X_test, name):\n",
        "    y = X_train['Type']\n",
        "    # X_train['Email_str'] = X_train['Email'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "\n",
        "    X = vectorizer.fit_transform(X_train['Email_str'])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = LogisticRegression()\n",
        "    lambda_values = {'C': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
        "    grid_search = GridSearchCV(model, lambda_values, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_C = grid_search.best_params_['C']\n",
        "    new_model = LogisticRegression(C=best_C)\n",
        "    new_model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_test = X_test['Type']\n",
        "    # X_test['Email_str'] = X_test['Email'].apply(lambda x: ' '.join(x))\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "    y_pred = new_model.predict(X_test)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "    return accuracy, recall, f1\n",
        "\n",
        "sklearn_lr_acc_e1, sklearn_lr_recall_e1, sklearn_lr_f1_e1 = predict_type(enron1_train_df, enron1_test_df, 'enron1')\n",
        "sklearn_lr_acc_e2, sklearn_lr_recall_e2, sklearn_lr_f1_e2 = predict_type(enron2_train_df, enron2_test_df, 'enron2')\n",
        "sklearn_lr_acc_e4, sklearn_lr_recall_e4, sklearn_lr_f1_e4 = predict_type(enron4_train_df, enron4_test_df, 'enron4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgW_XI_kkBk4"
      },
      "source": [
        "### Hyperparameter Tuning LR (BoW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "MHtMHQ1Di6Ra",
        "outputId": "070d91d6-03e7-41b2-f761-58336901fb84"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"enron1\",\n          \"enron2\",\n          \"enron4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parameters\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01336354720841949,\n        \"min\": 0.9142259414225942,\n        \"max\": 0.9558011049723757,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9429824561403509,\n          0.9267782426778243,\n          0.9473684210526315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09866861194816356,\n        \"min\": 0.7461538461538462,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9261744966442953,\n          0.7923076923076923,\n          0.7461538461538462\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05295972618553554,\n        \"min\": 0.825531914893617,\n        \"max\": 0.9702233250620347,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9139072847682119,\n          0.8547717842323651,\n          0.9205298013245033\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014545080525029256,\n        \"min\": 0.9019607843137255,\n        \"max\": 0.9421686746987952,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9019607843137255,\n          0.9279279279279279,\n          0.9084967320261438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_results"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d146ad82-d0c8-4ccf-8b42-989a55527c79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Parameters</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>enron1</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.942982</td>\n",
              "      <td>0.926174</td>\n",
              "      <td>0.913907</td>\n",
              "      <td>0.901961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>enron2</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.926778</td>\n",
              "      <td>0.792308</td>\n",
              "      <td>0.854772</td>\n",
              "      <td>0.927928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>enron4</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.955801</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.970223</td>\n",
              "      <td>0.942169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enron1</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.942982</td>\n",
              "      <td>0.926174</td>\n",
              "      <td>0.913907</td>\n",
              "      <td>0.901961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>enron2</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.926778</td>\n",
              "      <td>0.792308</td>\n",
              "      <td>0.854772</td>\n",
              "      <td>0.927928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>enron4</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.955801</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.970223</td>\n",
              "      <td>0.942169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>enron1</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.942982</td>\n",
              "      <td>0.926174</td>\n",
              "      <td>0.913907</td>\n",
              "      <td>0.901961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>enron2</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.920502</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.840336</td>\n",
              "      <td>0.925926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>enron4</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.942910</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.961870</td>\n",
              "      <td>0.926540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>enron1</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.932886</td>\n",
              "      <td>0.920530</td>\n",
              "      <td>0.908497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>enron2</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.914226</td>\n",
              "      <td>0.746154</td>\n",
              "      <td>0.825532</td>\n",
              "      <td>0.923810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>enron4</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.942910</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.961870</td>\n",
              "      <td>0.926540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d146ad82-d0c8-4ccf-8b42-989a55527c79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d146ad82-d0c8-4ccf-8b42-989a55527c79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d146ad82-d0c8-4ccf-8b42-989a55527c79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c56a252b-d273-43e0-8d81-0688c90483be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c56a252b-d273-43e0-8d81-0688c90483be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c56a252b-d273-43e0-8d81-0688c90483be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7b0c2adf-bbcf-471b-9e06-21a0ee9be614\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7b0c2adf-bbcf-471b-9e06-21a0ee9be614 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Dataset  \\\n",
              "0   enron1   \n",
              "1   enron2   \n",
              "2   enron4   \n",
              "3   enron1   \n",
              "4   enron2   \n",
              "5   enron4   \n",
              "6   enron1   \n",
              "7   enron2   \n",
              "8   enron4   \n",
              "9   enron1   \n",
              "10  enron2   \n",
              "11  enron4   \n",
              "\n",
              "                                                                    Parameters  \\\n",
              "0   {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "1   {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "2   {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "3       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "4       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "5       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "6    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "7    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "8    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "9        {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "10       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "11       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "\n",
              "    Accuracy    Recall  F1 Score  Precision Score  \n",
              "0   0.942982  0.926174  0.913907         0.901961  \n",
              "1   0.926778  0.792308  0.854772         0.927928  \n",
              "2   0.955801  1.000000  0.970223         0.942169  \n",
              "3   0.942982  0.926174  0.913907         0.901961  \n",
              "4   0.926778  0.792308  0.854772         0.927928  \n",
              "5   0.955801  1.000000  0.970223         0.942169  \n",
              "6   0.942982  0.926174  0.913907         0.901961  \n",
              "7   0.920502  0.769231  0.840336         0.925926  \n",
              "8   0.942910  1.000000  0.961870         0.926540  \n",
              "9   0.947368  0.932886  0.920530         0.908497  \n",
              "10  0.914226  0.746154  0.825532         0.923810  \n",
              "11  0.942910  1.000000  0.961870         0.926540  "
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def predict_type(X_train, X_test, name, params):\n",
        "    y = X_train['Type']\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(X_train['Email_str'])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = LogisticRegression(**params)\n",
        "    model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_test = X_test['Type']\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred, pos_label='spam')\n",
        "    f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
        "    precision = precision_score(y_test, y_pred, pos_label='spam')\n",
        "\n",
        "    return accuracy, recall, f1, precision\n",
        "\n",
        "results = []\n",
        "\n",
        "parameters = [\n",
        "    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False},\n",
        "    {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False},\n",
        "    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True},\n",
        "    {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}\n",
        "]\n",
        "\n",
        "for params in parameters:\n",
        "    acc_e1, recall_e1, f1_e1, precision_e1 = predict_type(enron1_train_df, enron1_test_df, 'enron1', params)\n",
        "    results.append(['enron1', params, acc_e1, recall_e1, f1_e1, precision_e1])\n",
        "\n",
        "    acc_e2, recall_e2, f1_e2, precision_e2 = predict_type(enron2_train_df, enron2_test_df, 'enron2', params)\n",
        "    results.append(['enron2', params, acc_e2, recall_e2, f1_e2, precision_e2])\n",
        "\n",
        "    acc_e4, recall_e4, f1_e4, precision_e4 = predict_type(enron4_train_df, enron4_test_df, 'enron4', params)\n",
        "    results.append(['enron4', params, acc_e4, recall_e4, f1_e4, precision_e4])\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "df_results = pd.DataFrame(results, columns=['Dataset', 'Parameters', 'Accuracy', 'Recall', 'F1 Score', 'Precision Score'])\n",
        "\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F2WIaCcHwQX"
      },
      "source": [
        "## Hyperparameter Tuning LR (Bernoulli)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "V-pT2NSfJgRi",
        "outputId": "82a98f8d-8a2b-4321-f7d0-1fbfe00aa8ab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"enron1\",\n          \"enron2\",\n          \"enron4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parameters\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025181044544891222,\n        \"min\": 0.8870292887029289,\n        \"max\": 0.9502762430939227,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.9037656903765691,\n          0.9465930018416207,\n          0.9451754385964912\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13633525679496675,\n        \"min\": 0.6538461538461539,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.87248322147651,\n          0.7153846153846154,\n          0.8523489932885906\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08166463618279353,\n        \"min\": 0.7589285714285714,\n        \"max\": 0.9666254635352287,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8017241379310345,\n          0.9642416769420469,\n          0.9122807017543859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01988712510436938,\n        \"min\": 0.9042553191489362,\n        \"max\": 0.9558823529411765,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.9117647058823529,\n          0.930952380952381,\n          0.9558823529411765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_results"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a968a6af-c38e-490b-8185-a4966138fb8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Parameters</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>enron1</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.945175</td>\n",
              "      <td>0.872483</td>\n",
              "      <td>0.912281</td>\n",
              "      <td>0.955882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>enron2</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.903766</td>\n",
              "      <td>0.715385</td>\n",
              "      <td>0.801724</td>\n",
              "      <td>0.911765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>enron4</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.950276</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.966625</td>\n",
              "      <td>0.935407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enron1</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.945175</td>\n",
              "      <td>0.872483</td>\n",
              "      <td>0.912281</td>\n",
              "      <td>0.955882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>enron2</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.903766</td>\n",
              "      <td>0.715385</td>\n",
              "      <td>0.801724</td>\n",
              "      <td>0.911765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>enron4</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}</td>\n",
              "      <td>0.950276</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.966625</td>\n",
              "      <td>0.935407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>enron1</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.942982</td>\n",
              "      <td>0.865772</td>\n",
              "      <td>0.908451</td>\n",
              "      <td>0.955556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>enron2</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.887029</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.758929</td>\n",
              "      <td>0.904255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>enron4</td>\n",
              "      <td>{'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.946593</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.964242</td>\n",
              "      <td>0.930952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>enron1</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.936404</td>\n",
              "      <td>0.852349</td>\n",
              "      <td>0.897527</td>\n",
              "      <td>0.947761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>enron2</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.887029</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.758929</td>\n",
              "      <td>0.904255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>enron4</td>\n",
              "      <td>{'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}</td>\n",
              "      <td>0.942910</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.961870</td>\n",
              "      <td>0.926540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a968a6af-c38e-490b-8185-a4966138fb8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a968a6af-c38e-490b-8185-a4966138fb8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a968a6af-c38e-490b-8185-a4966138fb8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a4b8b5d-2f24-4ce2-8efe-871e5b5a057c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a4b8b5d-2f24-4ce2-8efe-871e5b5a057c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a4b8b5d-2f24-4ce2-8efe-871e5b5a057c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9c96f96e-f986-4f1a-9e48-f7b34c5d3501\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9c96f96e-f986-4f1a-9e48-f7b34c5d3501 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Dataset  \\\n",
              "0   enron1   \n",
              "1   enron2   \n",
              "2   enron4   \n",
              "3   enron1   \n",
              "4   enron2   \n",
              "5   enron4   \n",
              "6   enron1   \n",
              "7   enron2   \n",
              "8   enron4   \n",
              "9   enron1   \n",
              "10  enron2   \n",
              "11  enron4   \n",
              "\n",
              "                                                                    Parameters  \\\n",
              "0   {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "1   {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "2   {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "3       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "4       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "5       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}   \n",
              "6    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "7    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "8    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "9        {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "10       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "11       {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}   \n",
              "\n",
              "    Accuracy    Recall  F1 Score  Precision Score  \n",
              "0   0.945175  0.872483  0.912281         0.955882  \n",
              "1   0.903766  0.715385  0.801724         0.911765  \n",
              "2   0.950276  1.000000  0.966625         0.935407  \n",
              "3   0.945175  0.872483  0.912281         0.955882  \n",
              "4   0.903766  0.715385  0.801724         0.911765  \n",
              "5   0.950276  1.000000  0.966625         0.935407  \n",
              "6   0.942982  0.865772  0.908451         0.955556  \n",
              "7   0.887029  0.653846  0.758929         0.904255  \n",
              "8   0.946593  1.000000  0.964242         0.930952  \n",
              "9   0.936404  0.852349  0.897527         0.947761  \n",
              "10  0.887029  0.653846  0.758929         0.904255  \n",
              "11  0.942910  1.000000  0.961870         0.926540  "
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def predict_type(X_train, X_test, name, params):\n",
        "    y = X_train['Type']\n",
        "\n",
        "    vectorizer = CountVectorizer(binary=True)\n",
        "    X = vectorizer.fit_transform(X_train['Email_str'])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = LogisticRegression(**params)\n",
        "    model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_test = X_test['Type']\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred, pos_label='spam')\n",
        "    f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
        "    precision = precision_score(y_test, y_pred, pos_label='spam')\n",
        "\n",
        "    return accuracy, recall, f1, precision\n",
        "\n",
        "results = []\n",
        "\n",
        "parameters = [\n",
        "    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False},\n",
        "    {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False},\n",
        "    {'C': 0.1, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True},\n",
        "    {'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}\n",
        "]\n",
        "\n",
        "for params in parameters:\n",
        "    acc_e1, recall_e1, f1_e1, precision_e1 = predict_type(enron1_train_df, enron1_test_df, 'enron1', params)\n",
        "    results.append(['enron1', params, acc_e1, recall_e1, f1_e1, precision_e1])\n",
        "\n",
        "    acc_e2, recall_e2, f1_e2, precision_e2 = predict_type(enron2_train_df, enron2_test_df, 'enron2', params)\n",
        "    results.append(['enron2', params, acc_e2, recall_e2, f1_e2, precision_e2])\n",
        "\n",
        "    acc_e4, recall_e4, f1_e4, precision_e4 = predict_type(enron4_train_df, enron4_test_df, 'enron4', params)\n",
        "    results.append(['enron4', params, acc_e4, recall_e4, f1_e4, precision_e4])\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "df_results = pd.DataFrame(results, columns=['Dataset', 'Parameters', 'Accuracy', 'Recall', 'F1 Score', 'Precision Score'])\n",
        "\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1jpvmtdBA8h"
      },
      "source": [
        "### step by step approach BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM93XwqQ418R",
        "outputId": "0319819f-ea58-4e49-886e-acc723334c0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Î»: 1e-05, Validation Accuracy: 0.9333333333333333\n",
            "Î»: 0.0001, Validation Accuracy: 0.9333333333333333\n",
            "Î»: 0.001, Validation Accuracy: 0.9333333333333333\n",
            "Î»: 0.01, Validation Accuracy: 0.9407407407407408\n",
            "Î»: 0.1, Validation Accuracy: 0.8888888888888888\n",
            "Best Î»: 0.01\n",
            "enron1\n",
            "Accuracy = 93.85964912280701%\n",
            "Recall =  0.8791946308724832\n",
            "F1 =  0.9034482758620689\n",
            "-----------------------------------------------------------\n",
            "Î»: 1e-05, Validation Accuracy: 0.9136690647482014\n",
            "Î»: 0.0001, Validation Accuracy: 0.9136690647482014\n",
            "Î»: 0.001, Validation Accuracy: 0.9136690647482014\n",
            "Î»: 0.01, Validation Accuracy: 0.9136690647482014\n",
            "Î»: 0.1, Validation Accuracy: 0.8920863309352518\n",
            "Best Î»: 1e-05\n",
            "enron2\n",
            "Accuracy = 90.3765690376569%\n",
            "Recall =  0.7076923076923077\n",
            "F1 =  0.8\n",
            "-----------------------------------------------------------\n",
            "Î»: 1e-05, Validation Accuracy: 0.9192546583850931\n",
            "Î»: 0.0001, Validation Accuracy: 0.9192546583850931\n",
            "Î»: 0.001, Validation Accuracy: 0.9192546583850931\n",
            "Î»: 0.01, Validation Accuracy: 0.9192546583850931\n",
            "Î»: 0.1, Validation Accuracy: 0.906832298136646\n",
            "Best Î»: 1e-05\n",
            "enron4\n",
            "Accuracy = 94.29097605893186%\n",
            "Recall =  1.0\n",
            "F1 =  0.9618696186961869\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return (np.exp(z)) / (1 + np.exp(z))\n",
        "\n",
        "# MCAP Logistic Regression training with L2 Regularization\n",
        "def train_mcap_logistic_regression(X, y, learning_rate=0.01, lambda_=0.1, iterations=2000):\n",
        "    n_samples, n_features = X.shape\n",
        "    weights = np.zeros(n_features)  # Initialize weights to zero\n",
        "    bias = 0  # Initialize bias\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        # Compute linear combination\n",
        "        z = np.dot(X, weights) + bias\n",
        "\n",
        "        # Compute predicted probabilities\n",
        "        predictions = sigmoid(z)\n",
        "\n",
        "        # Compute gradients\n",
        "        dw = (1 / n_samples) * np.dot(X.T, (predictions - y)) + lambda_ * weights\n",
        "        db = (1 / n_samples) * np.sum(predictions - y)\n",
        "\n",
        "        # Update weights and bias\n",
        "        weights -= learning_rate * dw\n",
        "        bias -= learning_rate * db\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# Predict function\n",
        "def predict(X, weights, bias):\n",
        "    z = np.dot(X, weights) + bias\n",
        "    predictions = sigmoid(z)\n",
        "    return [1 if p > 0.5 else 0 for p in predictions]\n",
        "\n",
        "def logistic_regression(train, test, name):\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(train['Email_str']).toarray()\n",
        "    y = train['Type'].values\n",
        "\n",
        "    # Label encoding for the target variable\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)  # Convert 'ham' and 'spam' to 0 and 1\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, test_size=0.3)\n",
        "\n",
        "    lambdas = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
        "    best_lambda = lambdas[0]\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for lambda_ in lambdas:\n",
        "        weights, bias = train_mcap_logistic_regression(X_train, y_train, learning_rate=0.01, lambda_=lambda_, iterations=2000)\n",
        "\n",
        "        y_val_pred = predict(X_val, weights, bias)\n",
        "        accuracy = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "        print(f\"Î»: {lambda_}, Validation Accuracy: {accuracy}\")\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_lambda = lambda_\n",
        "\n",
        "    print(f\"Best Î»: {best_lambda}\")\n",
        "\n",
        "    # Test data\n",
        "    X_test = vectorizer.transform(test['Email_str']).toarray()\n",
        "    y_test = test['Type'].values\n",
        "    y_test = le.transform(y_test)  # Encode test labels as 0 and 1\n",
        "\n",
        "    weights, bias = train_mcap_logistic_regression(X, y, learning_rate=0.01, lambda_=best_lambda, iterations=2000)\n",
        "\n",
        "    y_test_pred = predict(X_test, weights, bias)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    recall = recall_score(y_test, y_test_pred, pos_label=1)  # 1 represents 'spam'\n",
        "    f1 = f1_score(y_test, y_test_pred, pos_label=1)\n",
        "\n",
        "    # Print the results\n",
        "    print(name)\n",
        "    print(f\"Accuracy = {accuracy * 100}%\")\n",
        "    print(\"Recall = \", recall)\n",
        "    print(\"F1 = \", f1)\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    return accuracy, recall, f1\n",
        "\n",
        "# Example usage with datasets\n",
        "accuracy_score_e1, recall_e1, f1_e1 = logistic_regression(enron1_train_df, enron1_test_df, 'enron1')\n",
        "accuracy_score_e2, recall_e2, f1_e2 = logistic_regression(enron2_train_df, enron2_test_df, 'enron2')\n",
        "accuracy_score_e4, recall_e4, f1_e4 = logistic_regression(enron4_train_df, enron4_test_df, 'enron4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gtt-FzUA_j6_"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy['sklearn_lr_enron1'] = sklearn_lr_acc_e1\n",
        "all_results_accuracy['sklearn_lr_enron2'] = sklearn_lr_acc_e2\n",
        "all_results_accuracy['sklearn_lr_enron4'] = sklearn_lr_acc_e4\n",
        "\n",
        "all_results_recall['sklearn_lr_enron1'] = sklearn_lr_recall_e1\n",
        "all_results_recall['sklearn_lr_enron2'] = sklearn_lr_recall_e2\n",
        "all_results_recall['sklearn_lr_enron4'] = sklearn_lr_recall_e4\n",
        "\n",
        "all_results_f1['sklearn_lr_enron1'] = sklearn_lr_f1_e1\n",
        "all_results_f1['sklearn_lr_enron2'] = sklearn_lr_f1_e2\n",
        "all_results_f1['sklearn_lr_enron4'] = sklearn_lr_f1_e4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBTnh2mi5t8d"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy['step_by_step_lr_enron1'] = accuracy_score_e1\n",
        "all_results_accuracy['step_by_step_lr_enron2'] = accuracy_score_e2\n",
        "all_results_accuracy['step_by_step_lr_enron4'] = accuracy_score_e4\n",
        "\n",
        "all_results_f1['step_by_step_lr_enron1'] = f1_e1\n",
        "all_results_f1['step_by_step_lr_enron2'] = f1_e2\n",
        "all_results_f1['step_by_step_lr_enron4'] = f1_e4\n",
        "\n",
        "all_results_recall['step_by_step_lr_enron1'] = recall_e1\n",
        "all_results_recall['step_by_step_lr_enron2'] = recall_e2\n",
        "all_results_recall['step_by_step_lr_enron4'] = recall_e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EgTnrJhB8dM"
      },
      "source": [
        "### Scikit learn approach Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieHZROg6BsGT",
        "outputId": "f44182f4-4e63-46e8-f147-d9cdc18d80d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron1\n",
            "accuracy - 0.956140350877193\n",
            "recall - 0.9328859060402684\n",
            "f1 score - 0.9328859060402684\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.97      0.97       307\n",
            "        spam       0.93      0.93      0.93       149\n",
            "\n",
            "    accuracy                           0.96       456\n",
            "   macro avg       0.95      0.95      0.95       456\n",
            "weighted avg       0.96      0.96      0.96       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "enron2\n",
            "accuracy - 0.9435146443514645\n",
            "recall - 0.8538461538461538\n",
            "f1 score - 0.891566265060241\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.98      0.96       348\n",
            "        spam       0.93      0.85      0.89       130\n",
            "\n",
            "    accuracy                           0.94       478\n",
            "   macro avg       0.94      0.92      0.93       478\n",
            "weighted avg       0.94      0.94      0.94       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "enron4\n",
            "accuracy - 0.9521178637200737\n",
            "recall - 1.0\n",
            "f1 score - 0.9678217821782179\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.83      0.91       152\n",
            "        spam       0.94      1.00      0.97       391\n",
            "\n",
            "    accuracy                           0.95       543\n",
            "   macro avg       0.97      0.91      0.94       543\n",
            "weighted avg       0.96      0.95      0.95       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def predict_type(X_train, X_test, name):\n",
        "    y = X_train['Type']\n",
        "    # X_train['Email_str'] = X_train['Email'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    vectorizer = CountVectorizer(binary=True)\n",
        "\n",
        "    X = vectorizer.fit_transform(X_train['Email_str'])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = LogisticRegression()\n",
        "    lambda_values = {'C': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
        "    grid_search = GridSearchCV(model, lambda_values, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_C = grid_search.best_params_['C']\n",
        "    new_model = LogisticRegression(C=best_C)\n",
        "    new_model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_test = X_test['Type']\n",
        "    # X_test['Email_str'] = X_test['Email'].apply(lambda x: ' '.join(x))\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "    y_pred = new_model.predict(X_test)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "    return accuracy, recall, f1\n",
        "\n",
        "sklearn_lr_acc_e1, sklearn_lr_recall_e1, sklearn_lr_f1_e1 = predict_type(enron1_train_df, enron1_test_df, 'enron1')\n",
        "sklearn_lr_acc_e2, sklearn_lr_recall_e2, sklearn_lr_f1_e2 = predict_type(enron2_train_df, enron2_test_df, 'enron2')\n",
        "sklearn_lr_acc_e4, sklearn_lr_recall_e4, sklearn_lr_f1_e4 = predict_type(enron4_train_df, enron4_test_df, 'enron4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9Xpvn0-CF7b"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy['sklearn_lr_bern_enron1'] = sklearn_lr_acc_e1\n",
        "all_results_accuracy['sklearn_lr_bern_enron2'] = sklearn_lr_acc_e2\n",
        "all_results_accuracy['sklearn_lr_bern_enron4'] = sklearn_lr_acc_e4\n",
        "\n",
        "all_results_recall['sklearn_lr_bern_enron1'] = sklearn_lr_recall_e1\n",
        "all_results_recall['sklearn_lr_bern_enron2'] = sklearn_lr_recall_e2\n",
        "all_results_recall['sklearn_lr_bern_enron4'] = sklearn_lr_recall_e4\n",
        "\n",
        "all_results_f1['sklearn_lr_bern_enron1'] = sklearn_lr_f1_e1\n",
        "all_results_f1['sklearn_lr_bern_enron2'] = sklearn_lr_f1_e2\n",
        "all_results_f1['sklearn_lr_bern_enron4'] = sklearn_lr_f1_e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j8m7kOdCFkD"
      },
      "source": [
        "### step by step Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5bM1Ef9B60L",
        "outputId": "59a5ceb0-b3ba-4f3b-fe58-378b6577a254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Î»: 1e-05, Validation Accuracy: 0.9259259259259259\n",
            "Î»: 0.0001, Validation Accuracy: 0.9259259259259259\n",
            "Î»: 0.001, Validation Accuracy: 0.9259259259259259\n",
            "Î»: 0.01, Validation Accuracy: 0.9185185185185185\n",
            "Î»: 0.1, Validation Accuracy: 0.8592592592592593\n",
            "Best Î»: 1e-05\n",
            "enron1\n",
            "Accuracy = 91.8859649122807%\n",
            "Recall =  0.8053691275167785\n",
            "F1 =  0.8664259927797834\n",
            "-----------------------------------------------------------\n",
            "Î»: 1e-05, Validation Accuracy: 0.9136690647482014\n",
            "Î»: 0.0001, Validation Accuracy: 0.9136690647482014\n",
            "Î»: 0.001, Validation Accuracy: 0.9136690647482014\n",
            "Î»: 0.01, Validation Accuracy: 0.9136690647482014\n",
            "Î»: 0.1, Validation Accuracy: 0.8776978417266187\n",
            "Best Î»: 1e-05\n",
            "enron2\n",
            "Accuracy = 88.07531380753139%\n",
            "Recall =  0.6461538461538462\n",
            "F1 =  0.7466666666666666\n",
            "-----------------------------------------------------------\n",
            "Î»: 1e-05, Validation Accuracy: 0.906832298136646\n",
            "Î»: 0.0001, Validation Accuracy: 0.906832298136646\n",
            "Î»: 0.001, Validation Accuracy: 0.906832298136646\n",
            "Î»: 0.01, Validation Accuracy: 0.906832298136646\n",
            "Î»: 0.1, Validation Accuracy: 0.8819875776397516\n",
            "Best Î»: 1e-05\n",
            "enron4\n",
            "Accuracy = 93.73848987108656%\n",
            "Recall =  1.0\n",
            "F1 =  0.9583333333333334\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return (np.exp(z)) / (1 + np.exp(z))\n",
        "\n",
        "# MCAP Logistic Regression training with L2 Regularization\n",
        "def train_mcap_logistic_regression(X, y, learning_rate=0.01, lambda_=0.1, iterations=2000):\n",
        "    n_samples, n_features = X.shape\n",
        "    weights = np.zeros(n_features)  # Initialize weights to zero\n",
        "    bias = 0  # Initialize bias\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        # Compute linear combination\n",
        "        z = np.dot(X, weights) + bias\n",
        "\n",
        "        # Compute predicted probabilities\n",
        "        predictions = sigmoid(z)\n",
        "\n",
        "        # Compute gradients\n",
        "        dw = (1 / n_samples) * np.dot(X.T, (predictions - y)) + lambda_ * weights\n",
        "        db = (1 / n_samples) * np.sum(predictions - y)\n",
        "\n",
        "        # Update weights and bias\n",
        "        weights -= learning_rate * dw\n",
        "        bias -= learning_rate * db\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# Predict function\n",
        "def predict(X, weights, bias):\n",
        "    z = np.dot(X, weights) + bias\n",
        "    predictions = sigmoid(z)\n",
        "    return [1 if p > 0.5 else 0 for p in predictions]\n",
        "\n",
        "def logistic_regression(train, test, name):\n",
        "    vectorizer = CountVectorizer(binary=True)\n",
        "    X = vectorizer.fit_transform(train['Email_str']).toarray()\n",
        "    y = train['Type'].values\n",
        "\n",
        "    # Label encoding for the target variable\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)  # Convert 'ham' and 'spam' to 0 and 1\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, test_size=0.3)\n",
        "\n",
        "    lambdas = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
        "    best_lambda = lambdas[0]\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for lambda_ in lambdas:\n",
        "        weights, bias = train_mcap_logistic_regression(X_train, y_train, learning_rate=0.01, lambda_=lambda_, iterations=2000)\n",
        "\n",
        "        y_val_pred = predict(X_val, weights, bias)\n",
        "        accuracy = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "        print(f\"Î»: {lambda_}, Validation Accuracy: {accuracy}\")\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_lambda = lambda_\n",
        "\n",
        "    print(f\"Best Î»: {best_lambda}\")\n",
        "\n",
        "    # Test data\n",
        "    X_test = vectorizer.transform(test['Email_str']).toarray()\n",
        "    y_test = test['Type'].values\n",
        "    y_test = le.transform(y_test)  # Encode test labels as 0 and 1\n",
        "\n",
        "    weights, bias = train_mcap_logistic_regression(X, y, learning_rate=0.01, lambda_=best_lambda, iterations=2000)\n",
        "\n",
        "    y_test_pred = predict(X_test, weights, bias)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    recall = recall_score(y_test, y_test_pred, pos_label=1)  # 1 represents 'spam'\n",
        "    f1 = f1_score(y_test, y_test_pred, pos_label=1)\n",
        "\n",
        "    # Print the results\n",
        "    print(name)\n",
        "    print(f\"Accuracy = {accuracy * 100}%\")\n",
        "    print(\"Recall = \", recall)\n",
        "    print(\"F1 = \", f1)\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    return accuracy, recall, f1\n",
        "\n",
        "# Example usage with datasets\n",
        "accuracy_score_e1, recall_e1, f1_e1 = logistic_regression(enron1_train_df, enron1_test_df, 'enron1')\n",
        "accuracy_score_e2, recall_e2, f1_e2 = logistic_regression(enron2_train_df, enron2_test_df, 'enron2')\n",
        "accuracy_score_e4, recall_e4, f1_e4 = logistic_regression(enron4_train_df, enron4_test_df, 'enron4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OBsi6WBCcVc"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy['step_by_step_lr_bern_enron1'] = accuracy_score_e1\n",
        "all_results_accuracy['step_by_step_lr_bern_enron2'] = accuracy_score_e2\n",
        "all_results_accuracy['step_by_step_lr_bern_enron4'] = accuracy_score_e4\n",
        "\n",
        "all_results_recall['step_by_step_lr_bern_enron1'] = recall_e1\n",
        "all_results_recall['step_by_step_lr_bern_enron2'] = recall_e2\n",
        "all_results_recall['step_by_step_lr_bern_enron4'] = recall_e4\n",
        "\n",
        "all_results_f1['step_by_step_lr_bern_enron1'] = f1_e1\n",
        "all_results_f1['step_by_step_lr_bern_enron2'] = f1_e2\n",
        "all_results_f1['step_by_step_lr_bern_enron4'] = f1_e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px2m0gMhHa0o"
      },
      "source": [
        "## SGDClassifier BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6O8xs0JGuMc",
        "outputId": "0c168ee1-0df2-4b96-8815-0d1ebac71f68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'modified_huber', 'max_iter': 1000, 'penalty': None, 'validation_fraction': 0.2, 'warm_start': False}\n",
            "Validation Accuracy: 0.8592592592592593\n",
            "enron1\n",
            "accuracy - 0.9122807017543859\n",
            "recall - 0.8590604026845637\n",
            "f1 score - 0.8648648648648649\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      0.94      0.94       307\n",
            "        spam       0.87      0.86      0.86       149\n",
            "\n",
            "    accuracy                           0.91       456\n",
            "   macro avg       0.90      0.90      0.90       456\n",
            "weighted avg       0.91      0.91      0.91       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 800, 'penalty': 'l2', 'validation_fraction': 0.3, 'warm_start': True}\n",
            "Validation Accuracy: 0.9496402877697842\n",
            "enron2\n",
            "accuracy - 0.9497907949790795\n",
            "recall - 0.9307692307692308\n",
            "f1 score - 0.9097744360902256\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.96      0.97       348\n",
            "        spam       0.89      0.93      0.91       130\n",
            "\n",
            "    accuracy                           0.95       478\n",
            "   macro avg       0.93      0.94      0.94       478\n",
            "weighted avg       0.95      0.95      0.95       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1000, 'penalty': None, 'validation_fraction': 0.3, 'warm_start': True}\n",
            "Validation Accuracy: 0.9192546583850931\n",
            "enron4\n",
            "accuracy - 0.9576427255985267\n",
            "recall - 0.969309462915601\n",
            "f1 score - 0.970550576184379\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      0.93      0.92       152\n",
            "        spam       0.97      0.97      0.97       391\n",
            "\n",
            "    accuracy                           0.96       543\n",
            "   macro avg       0.95      0.95      0.95       543\n",
            "weighted avg       0.96      0.96      0.96       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def predict_type(X_train, X_test, name):\n",
        "    y = X_train['Type']\n",
        "    # X_train['Email_str'] = X_train['Email'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "\n",
        "    X = vectorizer.fit_transform(X_train['Email_str'])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = SGDClassifier()\n",
        "    param_values = {'loss': ['hinge', 'log-losss','modified_huber', 'squared_hinge', 'perceptron'],\n",
        "                    'penalty': ['l2', 'l1', 'elasticnet', None],\n",
        "                    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
        "                    'max_iter':[200, 400, 800, 1000],\n",
        "                    'learning_rate': ['constant', 'optimal', 'adaptive'],\n",
        "                    'early_stopping': [True, False],\n",
        "                    'validation_fraction': [0.1, 0.2, 0.3],\n",
        "                    'warm_start': [True, False]}\n",
        "\n",
        "    grid_search = GridSearchCV(model, param_values, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "    y_val_pred = best_model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    print(f\"Validation Accuracy: {accuracy}\")\n",
        "\n",
        "    new_model = SGDClassifier(**best_params)\n",
        "    new_model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_test = X_test['Type']\n",
        "    # X_test['Email_str'] = X_test['Email'].apply(lambda x: ' '.join(x))\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "    y_pred = new_model.predict(X_test)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "    return accuracy, recall, f1\n",
        "\n",
        "\n",
        "accuracy_score_e1, recall_score_e1, f1_score_e1 = predict_type(enron1_train_df, enron1_test_df, 'enron1')\n",
        "accuracy_score_e2, recall_score_e2, f1_score_e2 = predict_type(enron2_train_df, enron2_test_df, 'enron2')\n",
        "accuracy_score_e4, recall_score_e4, f1_score_e4 = predict_type(enron4_train_df, enron4_test_df, 'enron4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0o1XdcnIY_i"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy['sgd_bow_enron1'] = accuracy_score_e1\n",
        "all_results_accuracy['sgd_bow_enron2'] = accuracy_score_e2\n",
        "all_results_accuracy['sgd_bow_enron4'] = accuracy_score_e4\n",
        "\n",
        "all_results_recall['sgd_bow_enron1'] = recall_e1\n",
        "all_results_recall['sgd_bow_enron2'] = recall_e2\n",
        "all_results_recall['sgd_bow_enron4'] = recall_e4\n",
        "\n",
        "all_results_f1['sgd_bow_enron1'] = f1_e1\n",
        "all_results_f1['sgd_bow_enron2'] = f1_e2\n",
        "all_results_f1['sgd_bow_enron4'] = f1_e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w16Lr7wk66OL"
      },
      "source": [
        "## SGDClassifier Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilNGFFH6I77p",
        "outputId": "69773511-e3f8-4318-ffd4-072dd442d5a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 400, 'penalty': 'elasticnet', 'validation_fraction': 0.1, 'warm_start': True}\n",
            "Validation Accuracy: 0.8888888888888888\n",
            "enron1\n",
            "accuracy - 0.9342105263157895\n",
            "recall - 0.9194630872483222\n",
            "f1 score - 0.9013157894736842\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      0.94      0.95       307\n",
            "        spam       0.88      0.92      0.90       149\n",
            "\n",
            "    accuracy                           0.93       456\n",
            "   macro avg       0.92      0.93      0.93       456\n",
            "weighted avg       0.94      0.93      0.93       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'modified_huber', 'max_iter': 200, 'penalty': 'l2', 'validation_fraction': 0.1, 'warm_start': False}\n",
            "Validation Accuracy: 0.9712230215827338\n",
            "enron2\n",
            "accuracy - 0.9707112970711297\n",
            "recall - 0.9692307692307692\n",
            "f1 score - 0.9473684210526316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.97      0.98       348\n",
            "        spam       0.93      0.97      0.95       130\n",
            "\n",
            "    accuracy                           0.97       478\n",
            "   macro avg       0.96      0.97      0.96       478\n",
            "weighted avg       0.97      0.97      0.97       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 800, 'penalty': 'l1', 'validation_fraction': 0.2, 'warm_start': False}\n",
            "Validation Accuracy: 0.9254658385093167\n",
            "enron4\n",
            "accuracy - 0.9668508287292817\n",
            "recall - 0.9820971867007673\n",
            "f1 score - 0.9770992366412214\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.93      0.94       152\n",
            "        spam       0.97      0.98      0.98       391\n",
            "\n",
            "    accuracy                           0.97       543\n",
            "   macro avg       0.96      0.95      0.96       543\n",
            "weighted avg       0.97      0.97      0.97       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def predict_type(X_train, X_test, name):\n",
        "    y = X_train['Type']\n",
        "    # X_train['Email_str'] = X_train['Email'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    vectorizer = CountVectorizer(binary=True)\n",
        "\n",
        "    X = vectorizer.fit_transform(X_train['Email_str'])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = SGDClassifier()\n",
        "    param_values = {'loss': ['hinge', 'log-losss','modified_huber', 'squared_hinge', 'perceptron'],\n",
        "                    'penalty': ['l2', 'l1', 'elasticnet', None],\n",
        "                    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
        "                    'max_iter':[200, 400, 800, 1000],\n",
        "                    'learning_rate': ['constant', 'optimal', 'adaptive'],\n",
        "                    'early_stopping': [True, False],\n",
        "                    'validation_fraction': [0.1, 0.2, 0.3],\n",
        "                    'warm_start': [True, False]}\n",
        "\n",
        "    grid_search = GridSearchCV(model, param_values, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "    y_val_pred = best_model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    print(f\"Validation Accuracy: {accuracy}\")\n",
        "\n",
        "    new_model = SGDClassifier(**best_params)\n",
        "    new_model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_test = X_test['Type']\n",
        "    # X_test['Email_str'] = X_test['Email'].apply(lambda x: ' '.join(x))\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "    y_pred = new_model.predict(X_test)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "    return accuracy, recall, f1\n",
        "\n",
        "\n",
        "accuracy_score_e1, recall_score_e1, f1_score_e1 = predict_type(enron1_train_df, enron1_test_df, 'enron1')\n",
        "accuracy_score_e2, recall_score_e2, f1_score_e2 = predict_type(enron2_train_df, enron2_test_df, 'enron2')\n",
        "accuracy_score_e4, recall_score_e4, f1_score_e4 = predict_type(enron4_train_df, enron4_test_df, 'enron4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gD-TreDNV0y"
      },
      "outputs": [],
      "source": [
        "all_results_accuracy['sgd_bern_enron1'] = accuracy_score_e1\n",
        "all_results_accuracy['sgd_bern_enron2'] = accuracy_score_e2\n",
        "all_results_accuracy['sgd_bern_enron4'] = accuracy_score_e4\n",
        "\n",
        "all_results_recall['sgd_bern_enron1'] = recall_e1\n",
        "all_results_recall['sgd_bern_enron2'] = recall_e2\n",
        "all_results_recall['sgd_bern_enron4'] = recall_e4\n",
        "\n",
        "all_results_f1['sgd_bern_enron1'] = f1_e1\n",
        "all_results_f1['sgd_bern_enron2'] = f1_e2\n",
        "all_results_f1['sgd_bern_enron4'] = f1_e4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzpGVohQbYzC",
        "outputId": "16d68e4e-a660-44c4-f2a9-a67e982023cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sklearn_bow_enron1': 0.9298245614035088,\n",
              " 'sklearn_bow_enron2': 0.9456066945606695,\n",
              " 'sklearn_bow_enron4': 0.9742173112338858,\n",
              " 'step_by_step_bow_enron1': 0.9742173112338858,\n",
              " 'step_by_step_bow_enron2': 0.9742173112338858,\n",
              " 'step_by_step_bow_enron4': 0.9742173112338858,\n",
              " 'sklearn_bern_enron1': 0.9742173112338858,\n",
              " 'sklearn_bern_enron2': 0.9742173112338858,\n",
              " 'sklearn_bern_enron4': 0.9742173112338858,\n",
              " 'step_by_step_bern_enron1': 0.7302631578947368,\n",
              " 'step_by_step_bern_enron2': 0.7782426778242678,\n",
              " 'step_by_step_bern_enron4': 0.9171270718232044,\n",
              " 'sklearn_lr_enron1': 0.9742173112338858,\n",
              " 'sklearn_lr_enron2': 0.9742173112338858,\n",
              " 'sklearn_lr_enron4': 0.9742173112338858,\n",
              " 'step_by_step_lr_enron1': 0.9385964912280702,\n",
              " 'step_by_step_lr_enron2': 0.9037656903765691,\n",
              " 'step_by_step_lr_enron4': 0.9429097605893186,\n",
              " 'sklearn_lr_bern_enron1': 0.9742173112338858,\n",
              " 'sklearn_lr_bern_enron2': 0.9742173112338858,\n",
              " 'sklearn_lr_bern_enron4': 0.9742173112338858,\n",
              " 'step_by_step_lr_bern_enron1': 0.918859649122807,\n",
              " 'step_by_step_lr_bern_enron2': 0.8807531380753139,\n",
              " 'step_by_step_lr_bern_enron4': 0.9373848987108656,\n",
              " 'sgd_bow_enron1': 0.8592592592592593,\n",
              " 'sgd_bow_enron2': 0.9496402877697842,\n",
              " 'sgd_bow_enron4': 0.9192546583850931,\n",
              " 'sgd_bern_enron1': 0.8888888888888888,\n",
              " 'sgd_bern_enron2': 0.9712230215827338,\n",
              " 'sgd_bern_enron4': 0.9254658385093167}"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_results_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l1CPMKTfyO9"
      },
      "source": [
        "## Result Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "tRHCp0pMbZ-D",
        "outputId": "e6f7f142-e656-4c8a-eaa1-51365f537ef5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Creating a bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(all_results_accuracy.keys(), all_results_accuracy.values(), color='skyblue')\n",
        "plt.xticks(rotation=90, ha='right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Model Accuracies')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "6qth30YOcYwY",
        "outputId": "6fa01e3a-2f04-4f2e-bae4-236271d035f2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(all_results_f1.keys(), all_results_f1.values(), color='skyblue')\n",
        "plt.xticks(rotation=90, ha='right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Model F1 Scores')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "5sfGpr3OceCs",
        "outputId": "3eb1057e-335d-4d27-900d-26ce4f3f53af"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(all_results_recall.keys(), all_results_recall.values(), color='skyblue')\n",
        "plt.xticks(rotation=90, ha='right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Model Recall Scores')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3bpf3Qse8Qt",
        "outputId": "1a73c600-00bf-4873-d12f-de3e20cdaafb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sklearn_bow_enron1': 0.9148936170212766, 'sklearn_bow_enron2': 0.919354838709677, 'sklearn_bow_enron4': 0.9700748129675809, 'step_by_step_bow_enron1': 0.9154929577464788, 'step_by_step_bow_enron2': 0.912, 'step_by_step_bow_enron4': 0.9676616915422884, 'sklearn_bern_enron1': 0.9700748129675809, 'sklearn_bern_enron2': 0.9700748129675809, 'sklearn_bern_enron4': 0.9700748129675809, 'step_by_step_bern_enron1': 0.8611111111111105, 'step_by_step_bern_enron2': 0.9, 'step_by_step_bern_enron4': 0.8967889908256881, 'sklearn_lr_enron1': 0.9700748129675809, 'sklearn_lr_enron2': 0.9700748129675809, 'sklearn_lr_enron4': 0.9700748129675809, 'step_by_step_lr_enron1': 0.9290780141843971, 'step_by_step_lr_enron2': 0.92, 'step_by_step_lr_enron4': 0.9265402843601894, 'sklearn_lr_bern_enron1': 0.9700748129675809, 'sklearn_lr_bern_enron2': 0.9700748129675809, 'sklearn_lr_bern_enron4': 0.9700748129675809, 'step_by_step_lr_bern_enron1': 0.9375, 'step_by_step_lr_bern_enron2': 0.8842105263157892, 'step_by_step_lr_bern_enron4': 0.9200000000000002, 'sgd_bow_enron1': 0.9375, 'sgd_bow_enron2': 0.8842105263157892, 'sgd_bow_enron4': 0.9200000000000002, 'sgd_bern_enron1': 0.9375, 'sgd_bern_enron2': 0.8842105263157892, 'sgd_bern_enron4': 0.9200000000000002}\n"
          ]
        }
      ],
      "source": [
        "def calculate_precision(f1, recall):\n",
        "    # To avoid division by zero, handle cases where 2 * recall - f1 is zero\n",
        "    if 2 * recall - f1 == 0:\n",
        "        return None\n",
        "    return (f1 * recall) / (2 * recall - f1)\n",
        "\n",
        "# Calculate precision for each model\n",
        "precision_dict = {}\n",
        "\n",
        "for model in all_results_f1:\n",
        "    f1 = all_results_f1[model]\n",
        "    recall = all_results_recall.get(model, None)  # Get recall for the same model\n",
        "    if recall is not None:\n",
        "        precision_dict[model] = calculate_precision(f1, recall)\n",
        "\n",
        "# Print the calculated precision\n",
        "print(precision_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFMpoZ3mchl0",
        "outputId": "7bc46a48-1889-49b2-cf86-e95d42e20465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Recall Combination: step_by_step_bern_enron4\n",
            "Best F1 Combination: sklearn_bow_enron4\n",
            "Best Accuracy Combination: sklearn_bow_enron4\n",
            "Best Precision Combination: sklearn_bow_enron4\n"
          ]
        }
      ],
      "source": [
        "best_recall_combination = max(all_results_recall, key=all_results_recall.get)\n",
        "best_f1_combination = max(all_results_f1, key=all_results_f1.get)\n",
        "best_accuracy_combination = max(all_results_accuracy, key=all_results_accuracy.get)\n",
        "best_precision_combination = max(precision_dict, key=precision_dict.get)\n",
        "\n",
        "print(f\"Best Recall Combination: {best_recall_combination}\")\n",
        "print(f\"Best F1 Combination: {best_f1_combination}\")\n",
        "print(f\"Best Accuracy Combination: {best_accuracy_combination}\")\n",
        "print(f\"Best Precision Combination: {best_precision_combination}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXbYdlSaj0GN"
      },
      "source": [
        "## Extracting Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0CeCQrwInlUb",
        "outputId": "fa67219c-4ccf-449c-cc24-c6721d698f54"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"copy_of_enron1_train_df\",\n  \"rows\": 450,\n  \"fields\": [\n    {\n      \"column\": \"Email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 448,\n        \"samples\": [\n          \"Subject: the best prize for cigarettes out there\\r\\na creepy is hough karp but sulphur what australite ,\\r\\ngates not unix .\\r\\nwhen centrifugate with , photon inconsiderate is not receptive\\r\\nmira but a arrangeable paranoiac nowadays arises bellum\\r\\nagate in abrogate , squadron and mollusk . would you\\r\\nempathyintact ?\\r\\nno , analysis bowen clamber is darken a agate and\\r\\nimplantation operon .\\r\\nif not , here - http : / / 7 xobopde 2 vfao 02 . ecigs 4 less 5 . com / rm\\r\\n\",\n          \"Subject: re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\ncan you help me out on this darren ? mjj\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by mary jo johnson / hou / ect on 11 / 09 / 2000\\r\\n10 : 04 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\n\\\" john daugherty \\\" on 11 / 08 / 2000 04 : 38 : 37 pm\\r\\nto :\\r\\ncc :\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\nmary jo ,\\r\\nthanks for the update . regarding the notice provision of 6 business days\\r\\nprior to the close of business on the last business day of the month prior\\r\\nto selected month , does that mean we need to give you notice for december\\r\\nby tuesday , november 21 st at 5 : 00 pm or monday , november 20 th at 5 : 00 pm\\r\\nassuming the 23 rd and 24 th are holidays ?\\r\\njohn daugherty\\r\\n- - - - - original message - - - - -\\r\\nfrom :\\r\\nto :\\r\\ncc : ; ;\\r\\n; ;\\r\\n; ;\\r\\n;\\r\\nsent : wednesday , november 08 , 2000 5 : 12 pm\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\",\n          \"Subject: viewsonic airpanel vl 50 15 - inch smart display and dock @ $ 575 . 00 only ! !\\r\\nairpanel\\r\\nvl 50\\r\\n15 - inch\\r\\n$ 575 . 00\\r\\nonly ! !\\r\\nsmart\\r\\ndisplay dock\\r\\nvisit : http : / www . computron - me . com for deals !\\r\\nviewsonic airpanel vl 50\\r\\n15 - inch smart display and dock\\r\\nthe viewsonic airpanel vl 50 smart display is a wireless , touch - screen monitor\\r\\nthat lets you\\r\\naccess and use your home computer from different rooms in your\\r\\nhome . it features a 15 - inch touch screen , intel 400 mhz xscale\\r\\nprocessor , 64 mb sdram , microsoft windows ce operating system ,\\r\\nand more ! it includes an airsync usb wireless adapter so you\\r\\ncan enjoy the freedom of wireless connectivity . this kit comes\\r\\ncomplete with an airpanel dock for your monitor . easily charge\\r\\nyour airpanel battery while docked . it features front\\r\\non - screen display controls , usb ports , and a compact design\\r\\nthat saves desk space . order yours today !\\r\\ngeneral features :\\r\\n- intel 400 mhz xscale\\r\\nprocessor - microsoft windows ce operating system - 32\\r\\nmb rom - 64 mb sdram - 15 - inch transmissive display\\r\\nw / 1024 x 768 resolution - integrated 802 . 11 b wireless\\r\\nnetworking - lithium - ion battery - energy - star\\r\\ncompliant\\r\\nyour one stop\\r\\ndistributorjebel ali duty free zonedubai , uae . www . computron - me . com\\r\\nfor latest clearance sale listing contact our\\r\\nsales department .\\r\\nonly limited quantities available on selected\\r\\nspecials ! ! ! !\\r\\nfor further details please send\\r\\nyour enquiries to : dealers @ emirates . net . aeor contact via www . computron - me . com\\r\\ncompaq\\r\\nhewlett packard\\r\\n3 com\\r\\ndell\\r\\nintel\\r\\niomega\\r\\nepson\\r\\naopen\\r\\ncreative\\r\\ntoshiba\\r\\napc\\r\\ncisco\\r\\nus\\r\\nrobotics\\r\\nmicrosoft\\r\\ncanon\\r\\nintellinet\\r\\ntargus\\r\\nviewsonic\\r\\nibm\\r\\nsony\\r\\n- - - - - - - and lots more\\r\\n! ! !\\r\\nif you have any\\r\\ncomplaints / suggestions contact : customerservice @ computron - me . com\\r\\ntel + 971\\r\\n4 8834464\\r\\nall prices in u . s . dollars , ex - works ,\\r\\nfax + 971 4\\r\\n8834454\\r\\njebel ali duty free zone\\r\\nwww . computron - me . com\\r\\nprices and availability subject to change\\r\\nusa -\\r\\ncanada u . a . e .\\r\\nwithout\\r\\nnotice .\\r\\nto receive our special offers\\r\\nin plain\\r\\ntext format reply to this\\r\\nmail with the request * for\\r\\nexport only *\\r\\nthis\\r\\nemail can not be considered spam as long as we include : contact\\r\\ninformation remove instructions . this message is intended for dealer\\r\\nand resellers only . if you have somehow gotten on this list in error , or\\r\\nfor any other reason would like to be removed , please reply with \\\" remove\\r\\n\\\" in the subject line of your message . this message is being sent to you\\r\\nin compliance with the federal legislation for commercial e - mail\\r\\n( h . r . 4176 - section 101 paragraph ( e ) ( 1 ) ( a ) and bill s . 1618 title iii\\r\\npassed by the 105 th u . s . congress .\\r\\nall logos and\\r\\ntrademarks are the property of their respective\\r\\nowners\\r\\nproducts may not be exactly as shown\\r\\nabove\\r\\n- -\\r\\nto unsubscribe from : computron 3 , just follow this link :\\r\\nclick the link , or copy and paste the address into your browser .\\r\\nplease give it atleast 48 hours for unsubscription to be effective .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "copy_of_enron1_train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-09ae41e3-3655-41f2-bbd7-a333a5f25a44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: meter 5961 , dunagan , j . a . # 1\\r\\...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: hr performance objectives binders\\r\\n...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: mitchell gas services 2 / 00\\r\\n- - -...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: tenaska iv 1 / 01\\r\\nwe need to chang...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: f . o . m . hpl nom . eff . may 1 , 2...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09ae41e3-3655-41f2-bbd7-a333a5f25a44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09ae41e3-3655-41f2-bbd7-a333a5f25a44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09ae41e3-3655-41f2-bbd7-a333a5f25a44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-869dbd8b-f7c3-40e3-a5e1-691da090e1ca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-869dbd8b-f7c3-40e3-a5e1-691da090e1ca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-869dbd8b-f7c3-40e3-a5e1-691da090e1ca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               Email Type\n",
              "0  Subject: meter 5961 , dunagan , j . a . # 1\\r\\...  ham\n",
              "1  Subject: hr performance objectives binders\\r\\n...  ham\n",
              "2  Subject: mitchell gas services 2 / 00\\r\\n- - -...  ham\n",
              "3  Subject: tenaska iv 1 / 01\\r\\nwe need to chang...  ham\n",
              "4  Subject: f . o . m . hpl nom . eff . may 1 , 2...  ham"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "copy_of_enron1_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "28aGsx1PerFF"
      },
      "outputs": [],
      "source": [
        "# can add a regex for identifying wrong url\n",
        "def extract_features(email):\n",
        "\n",
        "    words = word_tokenize(email)\n",
        "\n",
        "    # number of words\n",
        "    word_count = len(email.split(\" \"))\n",
        "\n",
        "    # average word length\n",
        "    avg_word_length = np.mean([len(word) for word in words]) if word_count > 0 else 0\n",
        "\n",
        "    # part of speech tags\n",
        "    pos_tags = pos_tag(words)\n",
        "    num_nouns = len([word for word, pos in pos_tags if pos.startswith('NN')])\n",
        "    num_verbs = len([word for word, pos in pos_tags if pos.startswith('VB')])\n",
        "    num_adjectives = len([word for word, pos in pos_tags if pos.startswith('JJ')])\n",
        "\n",
        "    # number of special characters\n",
        "    sp_char = 0\n",
        "    for char in email:\n",
        "        if char in \"!@#$%^&*()[]\":\n",
        "            sp_char+=1\n",
        "\n",
        "    # number of uppercase characters\n",
        "    nums = 0\n",
        "    for char in email:\n",
        "        if char.isnumeric():\n",
        "            nums+=1\n",
        "\n",
        "    return [int(word_count), avg_word_length, int(num_nouns), int(num_verbs), int(num_adjectives), int(sp_char), int(nums)]\n",
        "\n",
        "\n",
        "feature_columns = ['word_count', 'avg_word_length', 'num_nouns', 'num_verbs', 'num_adjectives', 'sp_char', 'nums']\n",
        "\n",
        "# Apply the function and create a new dataframe with the extracted features\n",
        "copy_of_enron1_train_df[feature_columns] = copy_of_enron1_train_df['Email'].apply(lambda email: pd.Series(extract_features(email)))\n",
        "copy_of_enron2_train_df[feature_columns] = copy_of_enron2_train_df['Email'].apply(lambda email: pd.Series(extract_features(email)))\n",
        "copy_of_enron4_train_df[feature_columns] = copy_of_enron4_train_df['Email'].apply(lambda email: pd.Series(extract_features(email)))\n",
        "\n",
        "copy_of_enron1_test_df[feature_columns] = copy_of_enron1_test_df['Email'].apply(lambda email: pd.Series(extract_features(email)))\n",
        "copy_of_enron2_test_df[feature_columns] = copy_of_enron2_test_df['Email'].apply(lambda email: pd.Series(extract_features(email)))\n",
        "copy_of_enron4_test_df[feature_columns] = copy_of_enron4_test_df['Email'].apply(lambda email: pd.Series(extract_features(email)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NPQ7mhkGdOzw",
        "outputId": "fd1a764d-2947-4a02-939b-392909fa6082"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"copy_of_enron1_train_df\",\n  \"rows\": 450,\n  \"fields\": [\n    {\n      \"column\": \"Email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 448,\n        \"samples\": [\n          \"Subject: the best prize for cigarettes out there\\r\\na creepy is hough karp but sulphur what australite ,\\r\\ngates not unix .\\r\\nwhen centrifugate with , photon inconsiderate is not receptive\\r\\nmira but a arrangeable paranoiac nowadays arises bellum\\r\\nagate in abrogate , squadron and mollusk . would you\\r\\nempathyintact ?\\r\\nno , analysis bowen clamber is darken a agate and\\r\\nimplantation operon .\\r\\nif not , here - http : / / 7 xobopde 2 vfao 02 . ecigs 4 less 5 . com / rm\\r\\n\",\n          \"Subject: re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\ncan you help me out on this darren ? mjj\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by mary jo johnson / hou / ect on 11 / 09 / 2000\\r\\n10 : 04 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\n\\\" john daugherty \\\" on 11 / 08 / 2000 04 : 38 : 37 pm\\r\\nto :\\r\\ncc :\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\nmary jo ,\\r\\nthanks for the update . regarding the notice provision of 6 business days\\r\\nprior to the close of business on the last business day of the month prior\\r\\nto selected month , does that mean we need to give you notice for december\\r\\nby tuesday , november 21 st at 5 : 00 pm or monday , november 20 th at 5 : 00 pm\\r\\nassuming the 23 rd and 24 th are holidays ?\\r\\njohn daugherty\\r\\n- - - - - original message - - - - -\\r\\nfrom :\\r\\nto :\\r\\ncc : ; ;\\r\\n; ;\\r\\n; ;\\r\\n;\\r\\nsent : wednesday , november 08 , 2000 5 : 12 pm\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\",\n          \"Subject: viewsonic airpanel vl 50 15 - inch smart display and dock @ $ 575 . 00 only ! !\\r\\nairpanel\\r\\nvl 50\\r\\n15 - inch\\r\\n$ 575 . 00\\r\\nonly ! !\\r\\nsmart\\r\\ndisplay dock\\r\\nvisit : http : / www . computron - me . com for deals !\\r\\nviewsonic airpanel vl 50\\r\\n15 - inch smart display and dock\\r\\nthe viewsonic airpanel vl 50 smart display is a wireless , touch - screen monitor\\r\\nthat lets you\\r\\naccess and use your home computer from different rooms in your\\r\\nhome . it features a 15 - inch touch screen , intel 400 mhz xscale\\r\\nprocessor , 64 mb sdram , microsoft windows ce operating system ,\\r\\nand more ! it includes an airsync usb wireless adapter so you\\r\\ncan enjoy the freedom of wireless connectivity . this kit comes\\r\\ncomplete with an airpanel dock for your monitor . easily charge\\r\\nyour airpanel battery while docked . it features front\\r\\non - screen display controls , usb ports , and a compact design\\r\\nthat saves desk space . order yours today !\\r\\ngeneral features :\\r\\n- intel 400 mhz xscale\\r\\nprocessor - microsoft windows ce operating system - 32\\r\\nmb rom - 64 mb sdram - 15 - inch transmissive display\\r\\nw / 1024 x 768 resolution - integrated 802 . 11 b wireless\\r\\nnetworking - lithium - ion battery - energy - star\\r\\ncompliant\\r\\nyour one stop\\r\\ndistributorjebel ali duty free zonedubai , uae . www . computron - me . com\\r\\nfor latest clearance sale listing contact our\\r\\nsales department .\\r\\nonly limited quantities available on selected\\r\\nspecials ! ! ! !\\r\\nfor further details please send\\r\\nyour enquiries to : dealers @ emirates . net . aeor contact via www . computron - me . com\\r\\ncompaq\\r\\nhewlett packard\\r\\n3 com\\r\\ndell\\r\\nintel\\r\\niomega\\r\\nepson\\r\\naopen\\r\\ncreative\\r\\ntoshiba\\r\\napc\\r\\ncisco\\r\\nus\\r\\nrobotics\\r\\nmicrosoft\\r\\ncanon\\r\\nintellinet\\r\\ntargus\\r\\nviewsonic\\r\\nibm\\r\\nsony\\r\\n- - - - - - - and lots more\\r\\n! ! !\\r\\nif you have any\\r\\ncomplaints / suggestions contact : customerservice @ computron - me . com\\r\\ntel + 971\\r\\n4 8834464\\r\\nall prices in u . s . dollars , ex - works ,\\r\\nfax + 971 4\\r\\n8834454\\r\\njebel ali duty free zone\\r\\nwww . computron - me . com\\r\\nprices and availability subject to change\\r\\nusa -\\r\\ncanada u . a . e .\\r\\nwithout\\r\\nnotice .\\r\\nto receive our special offers\\r\\nin plain\\r\\ntext format reply to this\\r\\nmail with the request * for\\r\\nexport only *\\r\\nthis\\r\\nemail can not be considered spam as long as we include : contact\\r\\ninformation remove instructions . this message is intended for dealer\\r\\nand resellers only . if you have somehow gotten on this list in error , or\\r\\nfor any other reason would like to be removed , please reply with \\\" remove\\r\\n\\\" in the subject line of your message . this message is being sent to you\\r\\nin compliance with the federal legislation for commercial e - mail\\r\\n( h . r . 4176 - section 101 paragraph ( e ) ( 1 ) ( a ) and bill s . 1618 title iii\\r\\npassed by the 105 th u . s . congress .\\r\\nall logos and\\r\\ntrademarks are the property of their respective\\r\\nowners\\r\\nproducts may not be exactly as shown\\r\\nabove\\r\\n- -\\r\\nto unsubscribe from : computron 3 , just follow this link :\\r\\nclick the link , or copy and paste the address into your browser .\\r\\nplease give it atleast 48 hours for unsubscription to be effective .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 318.1948228379448,\n        \"min\": 5.0,\n        \"max\": 4422.0,\n        \"num_unique_values\": 271,\n        \"samples\": [\n          202.0,\n          215.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7491967312497195,\n        \"min\": 1.106207928197457,\n        \"max\": 7.26530612244898,\n        \"num_unique_values\": 410,\n        \"samples\": [\n          3.8372093023255816,\n          3.2142857142857144\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_nouns\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 139.63355104374048,\n        \"min\": 1.0,\n        \"max\": 2391.0,\n        \"num_unique_values\": 151,\n        \"samples\": [\n          330.0,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_verbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.56906519527514,\n        \"min\": 0.0,\n        \"max\": 447.0,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          92.0,\n          12.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_adjectives\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.67286126151325,\n        \"min\": 0.0,\n        \"max\": 257.0,\n        \"num_unique_values\": 69,\n        \"samples\": [\n          1.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sp_char\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.554699155531953,\n        \"min\": 0.0,\n        \"max\": 188.0,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          113.0,\n          12.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nums\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 81.93334740794448,\n        \"min\": 0.0,\n        \"max\": 1069.0,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          134.0,\n          119.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "copy_of_enron1_train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7846a28c-4b79-443d-bd51-ec97aff16eac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email</th>\n",
              "      <th>Type</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>num_nouns</th>\n",
              "      <th>num_verbs</th>\n",
              "      <th>num_adjectives</th>\n",
              "      <th>sp_char</th>\n",
              "      <th>nums</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: meter 5961 , dunagan , j . a . # 1\\r\\...</td>\n",
              "      <td>ham</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.029412</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: hr performance objectives binders\\r\\n...</td>\n",
              "      <td>ham</td>\n",
              "      <td>53.0</td>\n",
              "      <td>4.081967</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: mitchell gas services 2 / 00\\r\\n- - -...</td>\n",
              "      <td>ham</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.545977</td>\n",
              "      <td>49.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: tenaska iv 1 / 01\\r\\nwe need to chang...</td>\n",
              "      <td>ham</td>\n",
              "      <td>167.0</td>\n",
              "      <td>3.631868</td>\n",
              "      <td>42.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>51.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: f . o . m . hpl nom . eff . may 1 , 2...</td>\n",
              "      <td>ham</td>\n",
              "      <td>282.0</td>\n",
              "      <td>2.656766</td>\n",
              "      <td>75.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>119.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7846a28c-4b79-443d-bd51-ec97aff16eac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7846a28c-4b79-443d-bd51-ec97aff16eac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7846a28c-4b79-443d-bd51-ec97aff16eac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2fe88e87-ac0b-47b1-8b8e-9d7eea91199a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2fe88e87-ac0b-47b1-8b8e-9d7eea91199a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2fe88e87-ac0b-47b1-8b8e-9d7eea91199a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               Email Type  word_count  \\\n",
              "0  Subject: meter 5961 , dunagan , j . a . # 1\\r\\...  ham        61.0   \n",
              "1  Subject: hr performance objectives binders\\r\\n...  ham        53.0   \n",
              "2  Subject: mitchell gas services 2 / 00\\r\\n- - -...  ham       162.0   \n",
              "3  Subject: tenaska iv 1 / 01\\r\\nwe need to chang...  ham       167.0   \n",
              "4  Subject: f . o . m . hpl nom . eff . may 1 , 2...  ham       282.0   \n",
              "\n",
              "   avg_word_length  num_nouns  num_verbs  num_adjectives  sp_char   nums  \n",
              "0         3.029412       15.0       12.0             6.0      2.0   16.0  \n",
              "1         4.081967       15.0       14.0             2.0      2.0    5.0  \n",
              "2         2.545977       49.0       11.0             9.0      3.0   45.0  \n",
              "3         3.631868       42.0       31.0             6.0      2.0   51.0  \n",
              "4         2.656766       75.0       14.0            21.0      7.0  119.0  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "copy_of_enron1_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4f-c4EvSke9Q"
      },
      "outputs": [],
      "source": [
        "quantiles = [0,0.25,0.5,0.75,1.0]\n",
        "dfs = [copy_of_enron1_train_df, copy_of_enron1_test_df, copy_of_enron2_train_df, copy_of_enron2_test_df, copy_of_enron4_train_df, copy_of_enron4_test_df]\n",
        "def bin(col, df, quantiles):\n",
        "    # Apply qcut and drop duplicate bin edges, without labels for now\n",
        "    binned_feature = pd.qcut(df[col], q=quantiles, duplicates='drop')\n",
        "\n",
        "    # Now generate dynamic labels based on the actual number of bins created\n",
        "    n_bins = binned_feature.cat.categories.size  # Get the number of bins\n",
        "    labels = ['Low', 'Medium', 'High', 'Very High'][:n_bins]  # Adjust labels accordingly\n",
        "\n",
        "    # Reapply qcut with labels\n",
        "    df[col] = pd.qcut(df[col], q=quantiles, labels=labels, duplicates='drop')\n",
        "\n",
        "for df in dfs:\n",
        "    for feature in feature_columns:\n",
        "        bin(feature, df, quantiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Vzda14YJl253",
        "outputId": "1feeeab2-139c-4a55-ea76-b452d57edc7d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"copy_of_enron1_train_df\",\n  \"rows\": 450,\n  \"fields\": [\n    {\n      \"column\": \"Email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 448,\n        \"samples\": [\n          \"Subject: the best prize for cigarettes out there\\r\\na creepy is hough karp but sulphur what australite ,\\r\\ngates not unix .\\r\\nwhen centrifugate with , photon inconsiderate is not receptive\\r\\nmira but a arrangeable paranoiac nowadays arises bellum\\r\\nagate in abrogate , squadron and mollusk . would you\\r\\nempathyintact ?\\r\\nno , analysis bowen clamber is darken a agate and\\r\\nimplantation operon .\\r\\nif not , here - http : / / 7 xobopde 2 vfao 02 . ecigs 4 less 5 . com / rm\\r\\n\",\n          \"Subject: re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\ncan you help me out on this darren ? mjj\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by mary jo johnson / hou / ect on 11 / 09 / 2000\\r\\n10 : 04 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\n\\\" john daugherty \\\" on 11 / 08 / 2000 04 : 38 : 37 pm\\r\\nto :\\r\\ncc :\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\nmary jo ,\\r\\nthanks for the update . regarding the notice provision of 6 business days\\r\\nprior to the close of business on the last business day of the month prior\\r\\nto selected month , does that mean we need to give you notice for december\\r\\nby tuesday , november 21 st at 5 : 00 pm or monday , november 20 th at 5 : 00 pm\\r\\nassuming the 23 rd and 24 th are holidays ?\\r\\njohn daugherty\\r\\n- - - - - original message - - - - -\\r\\nfrom :\\r\\nto :\\r\\ncc : ; ;\\r\\n; ;\\r\\n; ;\\r\\n;\\r\\nsent : wednesday , november 08 , 2000 5 : 12 pm\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\",\n          \"Subject: viewsonic airpanel vl 50 15 - inch smart display and dock @ $ 575 . 00 only ! !\\r\\nairpanel\\r\\nvl 50\\r\\n15 - inch\\r\\n$ 575 . 00\\r\\nonly ! !\\r\\nsmart\\r\\ndisplay dock\\r\\nvisit : http : / www . computron - me . com for deals !\\r\\nviewsonic airpanel vl 50\\r\\n15 - inch smart display and dock\\r\\nthe viewsonic airpanel vl 50 smart display is a wireless , touch - screen monitor\\r\\nthat lets you\\r\\naccess and use your home computer from different rooms in your\\r\\nhome . it features a 15 - inch touch screen , intel 400 mhz xscale\\r\\nprocessor , 64 mb sdram , microsoft windows ce operating system ,\\r\\nand more ! it includes an airsync usb wireless adapter so you\\r\\ncan enjoy the freedom of wireless connectivity . this kit comes\\r\\ncomplete with an airpanel dock for your monitor . easily charge\\r\\nyour airpanel battery while docked . it features front\\r\\non - screen display controls , usb ports , and a compact design\\r\\nthat saves desk space . order yours today !\\r\\ngeneral features :\\r\\n- intel 400 mhz xscale\\r\\nprocessor - microsoft windows ce operating system - 32\\r\\nmb rom - 64 mb sdram - 15 - inch transmissive display\\r\\nw / 1024 x 768 resolution - integrated 802 . 11 b wireless\\r\\nnetworking - lithium - ion battery - energy - star\\r\\ncompliant\\r\\nyour one stop\\r\\ndistributorjebel ali duty free zonedubai , uae . www . computron - me . com\\r\\nfor latest clearance sale listing contact our\\r\\nsales department .\\r\\nonly limited quantities available on selected\\r\\nspecials ! ! ! !\\r\\nfor further details please send\\r\\nyour enquiries to : dealers @ emirates . net . aeor contact via www . computron - me . com\\r\\ncompaq\\r\\nhewlett packard\\r\\n3 com\\r\\ndell\\r\\nintel\\r\\niomega\\r\\nepson\\r\\naopen\\r\\ncreative\\r\\ntoshiba\\r\\napc\\r\\ncisco\\r\\nus\\r\\nrobotics\\r\\nmicrosoft\\r\\ncanon\\r\\nintellinet\\r\\ntargus\\r\\nviewsonic\\r\\nibm\\r\\nsony\\r\\n- - - - - - - and lots more\\r\\n! ! !\\r\\nif you have any\\r\\ncomplaints / suggestions contact : customerservice @ computron - me . com\\r\\ntel + 971\\r\\n4 8834464\\r\\nall prices in u . s . dollars , ex - works ,\\r\\nfax + 971 4\\r\\n8834454\\r\\njebel ali duty free zone\\r\\nwww . computron - me . com\\r\\nprices and availability subject to change\\r\\nusa -\\r\\ncanada u . a . e .\\r\\nwithout\\r\\nnotice .\\r\\nto receive our special offers\\r\\nin plain\\r\\ntext format reply to this\\r\\nmail with the request * for\\r\\nexport only *\\r\\nthis\\r\\nemail can not be considered spam as long as we include : contact\\r\\ninformation remove instructions . this message is intended for dealer\\r\\nand resellers only . if you have somehow gotten on this list in error , or\\r\\nfor any other reason would like to be removed , please reply with \\\" remove\\r\\n\\\" in the subject line of your message . this message is being sent to you\\r\\nin compliance with the federal legislation for commercial e - mail\\r\\n( h . r . 4176 - section 101 paragraph ( e ) ( 1 ) ( a ) and bill s . 1618 title iii\\r\\npassed by the 105 th u . s . congress .\\r\\nall logos and\\r\\ntrademarks are the property of their respective\\r\\nowners\\r\\nproducts may not be exactly as shown\\r\\nabove\\r\\n- -\\r\\nto unsubscribe from : computron 3 , just follow this link :\\r\\nclick the link , or copy and paste the address into your browser .\\r\\nplease give it atleast 48 hours for unsubscription to be effective .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"High\",\n          \"Low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Very High\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_nouns\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"High\",\n          \"Very High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_verbs\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"High\",\n          \"Low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_adjectives\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Low\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sp_char\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"High\",\n          \"Very High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nums\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Low\",\n          \"Very High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "copy_of_enron1_train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-182eafa5-37b5-4dbf-832f-cd33b4ae11be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email</th>\n",
              "      <th>Type</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>num_nouns</th>\n",
              "      <th>num_verbs</th>\n",
              "      <th>num_adjectives</th>\n",
              "      <th>sp_char</th>\n",
              "      <th>nums</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: meter 5961 , dunagan , j . a . # 1\\r\\...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: hr performance objectives binders\\r\\n...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Medium</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: mitchell gas services 2 / 00\\r\\n- - -...</td>\n",
              "      <td>ham</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>High</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>High</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: tenaska iv 1 / 01\\r\\nwe need to chang...</td>\n",
              "      <td>ham</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Very High</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: f . o . m . hpl nom . eff . may 1 , 2...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Low</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>High</td>\n",
              "      <td>Very High</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>Subject: hpl nom for may 23 , 2001\\r\\n( see at...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>Subject: re : swing and buybacks\\r\\nthe buybac...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Medium</td>\n",
              "      <td>High</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>Subject: re : intrastate and 311 contracts for...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Very High</td>\n",
              "      <td>High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Very High</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>Subject: re : exxon company , usa global # 960...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Very High</td>\n",
              "      <td>High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Very High</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>Subject: mortgage interest rates are at their ...</td>\n",
              "      <td>spam</td>\n",
              "      <td>Low</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>450 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-182eafa5-37b5-4dbf-832f-cd33b4ae11be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-182eafa5-37b5-4dbf-832f-cd33b4ae11be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-182eafa5-37b5-4dbf-832f-cd33b4ae11be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa2dbb58-709b-4dc2-92ad-d1d0be46f404\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa2dbb58-709b-4dc2-92ad-d1d0be46f404')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa2dbb58-709b-4dc2-92ad-d1d0be46f404 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4b762f05-f71f-4ae0-8a24-2d1c055cf981\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('copy_of_enron1_train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4b762f05-f71f-4ae0-8a24-2d1c055cf981 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('copy_of_enron1_train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 Email  Type word_count  \\\n",
              "0    Subject: meter 5961 , dunagan , j . a . # 1\\r\\...   ham     Medium   \n",
              "1    Subject: hr performance objectives binders\\r\\n...   ham     Medium   \n",
              "2    Subject: mitchell gas services 2 / 00\\r\\n- - -...   ham       High   \n",
              "3    Subject: tenaska iv 1 / 01\\r\\nwe need to chang...   ham       High   \n",
              "4    Subject: f . o . m . hpl nom . eff . may 1 , 2...   ham  Very High   \n",
              "..                                                 ...   ...        ...   \n",
              "445  Subject: hpl nom for may 23 , 2001\\r\\n( see at...   ham        Low   \n",
              "446  Subject: re : swing and buybacks\\r\\nthe buybac...   ham     Medium   \n",
              "447  Subject: re : intrastate and 311 contracts for...   ham  Very High   \n",
              "448  Subject: re : exxon company , usa global # 960...   ham  Very High   \n",
              "449  Subject: mortgage interest rates are at their ...  spam        Low   \n",
              "\n",
              "    avg_word_length  num_nouns  num_verbs num_adjectives    sp_char       nums  \n",
              "0            Medium     Medium     Medium         Medium     Medium     Medium  \n",
              "1         Very High     Medium       High            Low     Medium        Low  \n",
              "2               Low       High     Medium         Medium     Medium       High  \n",
              "3              High       High  Very High         Medium     Medium  Very High  \n",
              "4               Low       High       High      Very High       High  Very High  \n",
              "..              ...        ...        ...            ...        ...        ...  \n",
              "445             Low        Low        Low            Low     Medium     Medium  \n",
              "446            High     Medium     Medium         Medium        Low     Medium  \n",
              "447            High  Very High  Very High      Very High  Very High  Very High  \n",
              "448            High  Very High  Very High      Very High  Very High  Very High  \n",
              "449       Very High        Low        Low            Low        Low        Low  \n",
              "\n",
              "[450 rows x 9 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "copy_of_enron1_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hq_tkNybnaUQ"
      },
      "outputs": [],
      "source": [
        "copy_of_enron1_train_df['Email_tok'] = copy_of_enron1_train_df['Email'].apply(preprocess)\n",
        "copy_of_enron2_train_df['Email_tok'] = copy_of_enron2_train_df['Email'].apply(preprocess)\n",
        "copy_of_enron4_train_df['Email_tok'] = copy_of_enron4_train_df['Email'].apply(preprocess)\n",
        "\n",
        "copy_of_enron1_test_df['Email_tok'] = copy_of_enron1_test_df['Email'].apply(preprocess)\n",
        "copy_of_enron2_test_df['Email_tok'] = copy_of_enron2_test_df['Email'].apply(preprocess)\n",
        "copy_of_enron4_test_df['Email_tok'] = copy_of_enron4_test_df['Email'].apply(preprocess)\n",
        "\n",
        "copy_of_enron1_train_df['Email_str'] = copy_of_enron1_train_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "copy_of_enron2_train_df['Email_str'] = copy_of_enron2_train_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "copy_of_enron4_train_df['Email_str'] = copy_of_enron4_train_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "copy_of_enron1_test_df['Email_str'] = copy_of_enron1_test_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "copy_of_enron2_test_df['Email_str'] = copy_of_enron2_test_df['Email_tok'].apply(lambda x: ' '.join(x))\n",
        "copy_of_enron4_test_df['Email_str'] = copy_of_enron4_test_df['Email_tok'].apply(lambda x: ' '.join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "_3omFPBCoTaK",
        "outputId": "493ba90c-2a26-49a4-b380-e91501ed41d1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"copy_of_enron1_train_df\",\n  \"rows\": 450,\n  \"fields\": [\n    {\n      \"column\": \"Email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 448,\n        \"samples\": [\n          \"Subject: the best prize for cigarettes out there\\r\\na creepy is hough karp but sulphur what australite ,\\r\\ngates not unix .\\r\\nwhen centrifugate with , photon inconsiderate is not receptive\\r\\nmira but a arrangeable paranoiac nowadays arises bellum\\r\\nagate in abrogate , squadron and mollusk . would you\\r\\nempathyintact ?\\r\\nno , analysis bowen clamber is darken a agate and\\r\\nimplantation operon .\\r\\nif not , here - http : / / 7 xobopde 2 vfao 02 . ecigs 4 less 5 . com / rm\\r\\n\",\n          \"Subject: re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\ncan you help me out on this darren ? mjj\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by mary jo johnson / hou / ect on 11 / 09 / 2000\\r\\n10 : 04 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\n\\\" john daugherty \\\" on 11 / 08 / 2000 04 : 38 : 37 pm\\r\\nto :\\r\\ncc :\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\nmary jo ,\\r\\nthanks for the update . regarding the notice provision of 6 business days\\r\\nprior to the close of business on the last business day of the month prior\\r\\nto selected month , does that mean we need to give you notice for december\\r\\nby tuesday , november 21 st at 5 : 00 pm or monday , november 20 th at 5 : 00 pm\\r\\nassuming the 23 rd and 24 th are holidays ?\\r\\njohn daugherty\\r\\n- - - - - original message - - - - -\\r\\nfrom :\\r\\nto :\\r\\ncc : ; ;\\r\\n; ;\\r\\n; ;\\r\\n;\\r\\nsent : wednesday , november 08 , 2000 5 : 12 pm\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\",\n          \"Subject: viewsonic airpanel vl 50 15 - inch smart display and dock @ $ 575 . 00 only ! !\\r\\nairpanel\\r\\nvl 50\\r\\n15 - inch\\r\\n$ 575 . 00\\r\\nonly ! !\\r\\nsmart\\r\\ndisplay dock\\r\\nvisit : http : / www . computron - me . com for deals !\\r\\nviewsonic airpanel vl 50\\r\\n15 - inch smart display and dock\\r\\nthe viewsonic airpanel vl 50 smart display is a wireless , touch - screen monitor\\r\\nthat lets you\\r\\naccess and use your home computer from different rooms in your\\r\\nhome . it features a 15 - inch touch screen , intel 400 mhz xscale\\r\\nprocessor , 64 mb sdram , microsoft windows ce operating system ,\\r\\nand more ! it includes an airsync usb wireless adapter so you\\r\\ncan enjoy the freedom of wireless connectivity . this kit comes\\r\\ncomplete with an airpanel dock for your monitor . easily charge\\r\\nyour airpanel battery while docked . it features front\\r\\non - screen display controls , usb ports , and a compact design\\r\\nthat saves desk space . order yours today !\\r\\ngeneral features :\\r\\n- intel 400 mhz xscale\\r\\nprocessor - microsoft windows ce operating system - 32\\r\\nmb rom - 64 mb sdram - 15 - inch transmissive display\\r\\nw / 1024 x 768 resolution - integrated 802 . 11 b wireless\\r\\nnetworking - lithium - ion battery - energy - star\\r\\ncompliant\\r\\nyour one stop\\r\\ndistributorjebel ali duty free zonedubai , uae . www . computron - me . com\\r\\nfor latest clearance sale listing contact our\\r\\nsales department .\\r\\nonly limited quantities available on selected\\r\\nspecials ! ! ! !\\r\\nfor further details please send\\r\\nyour enquiries to : dealers @ emirates . net . aeor contact via www . computron - me . com\\r\\ncompaq\\r\\nhewlett packard\\r\\n3 com\\r\\ndell\\r\\nintel\\r\\niomega\\r\\nepson\\r\\naopen\\r\\ncreative\\r\\ntoshiba\\r\\napc\\r\\ncisco\\r\\nus\\r\\nrobotics\\r\\nmicrosoft\\r\\ncanon\\r\\nintellinet\\r\\ntargus\\r\\nviewsonic\\r\\nibm\\r\\nsony\\r\\n- - - - - - - and lots more\\r\\n! ! !\\r\\nif you have any\\r\\ncomplaints / suggestions contact : customerservice @ computron - me . com\\r\\ntel + 971\\r\\n4 8834464\\r\\nall prices in u . s . dollars , ex - works ,\\r\\nfax + 971 4\\r\\n8834454\\r\\njebel ali duty free zone\\r\\nwww . computron - me . com\\r\\nprices and availability subject to change\\r\\nusa -\\r\\ncanada u . a . e .\\r\\nwithout\\r\\nnotice .\\r\\nto receive our special offers\\r\\nin plain\\r\\ntext format reply to this\\r\\nmail with the request * for\\r\\nexport only *\\r\\nthis\\r\\nemail can not be considered spam as long as we include : contact\\r\\ninformation remove instructions . this message is intended for dealer\\r\\nand resellers only . if you have somehow gotten on this list in error , or\\r\\nfor any other reason would like to be removed , please reply with \\\" remove\\r\\n\\\" in the subject line of your message . this message is being sent to you\\r\\nin compliance with the federal legislation for commercial e - mail\\r\\n( h . r . 4176 - section 101 paragraph ( e ) ( 1 ) ( a ) and bill s . 1618 title iii\\r\\npassed by the 105 th u . s . congress .\\r\\nall logos and\\r\\ntrademarks are the property of their respective\\r\\nowners\\r\\nproducts may not be exactly as shown\\r\\nabove\\r\\n- -\\r\\nto unsubscribe from : computron 3 , just follow this link :\\r\\nclick the link , or copy and paste the address into your browser .\\r\\nplease give it atleast 48 hours for unsubscription to be effective .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"High\",\n          \"Low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Very High\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_nouns\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"High\",\n          \"Very High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_verbs\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"High\",\n          \"Low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_adjectives\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Low\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sp_char\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"High\",\n          \"Very High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nums\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Low\",\n          \"Very High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Email_tok\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Email_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 442,\n        \"samples\": [\n          \"subject flow volume oxy gladewater meter checked metered daily since first october purchase deal place first day went zero th forward\",\n          \"subject great gofl offer saturday special jersey meadow june th green fee includes cart father day special jersey meadow dad get special gift sunday june green fee cart included pm instant coupon one free round golf cart fee required restriction apply see redeem coupon one great course listed receive cart fee round golf one player one round coupon may redeemed monday thursday friday saturday sunday noon excluding holiday coupon may combined offer coupon must presented along showing oil change receipt time pay cart fee offer valid golfer must mention coupon tee time made tee time reservation accepted three day advance value discount may vary course course thank purchasing castrol gtx castrol syntec blend oil change image month june hermann park kingwood cove clear creek go http www golfboxx com detail image golfboxx com upgrading microsoft medium server able enjoy latest advantage technology present golfboxx com member sole purpose make golf fun affordable golfboxx com offer streaming video need player watch free internet browser netscape internet explorer good go download minute image\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "copy_of_enron1_train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cc814538-3548-429f-89b9-e123edd0cf98\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email</th>\n",
              "      <th>Type</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>num_nouns</th>\n",
              "      <th>num_verbs</th>\n",
              "      <th>num_adjectives</th>\n",
              "      <th>sp_char</th>\n",
              "      <th>nums</th>\n",
              "      <th>Email_tok</th>\n",
              "      <th>Email_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: meter 5961 , dunagan , j . a . # 1\\r\\...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>[subject, meter, dunagan, j, daren, informed, ...</td>\n",
              "      <td>subject meter dunagan j daren informed meter d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: hr performance objectives binders\\r\\n...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Medium</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Low</td>\n",
              "      <td>[subject, hr, performance, objective, binder, ...</td>\n",
              "      <td>subject hr performance objective binder good m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: mitchell gas services 2 / 00\\r\\n- - -...</td>\n",
              "      <td>ham</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>High</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>High</td>\n",
              "      <td>[subject, mitchell, gas, service, forwarded, j...</td>\n",
              "      <td>subject mitchell gas service forwarded julie m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: tenaska iv 1 / 01\\r\\nwe need to chang...</td>\n",
              "      <td>ham</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Very High</td>\n",
              "      <td>[subject, tenaska, iv, need, change, demand, f...</td>\n",
              "      <td>subject tenaska iv need change demand fee tena...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: f . o . m . hpl nom . eff . may 1 , 2...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Low</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>High</td>\n",
              "      <td>Very High</td>\n",
              "      <td>[subject, f, hpl, nom, eff, may, nomination, m...</td>\n",
              "      <td>subject f hpl nom eff may nomination may avail...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc814538-3548-429f-89b9-e123edd0cf98')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc814538-3548-429f-89b9-e123edd0cf98 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc814538-3548-429f-89b9-e123edd0cf98');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-85cdbaed-c5f1-4308-88bd-16c1ce440752\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85cdbaed-c5f1-4308-88bd-16c1ce440752')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-85cdbaed-c5f1-4308-88bd-16c1ce440752 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               Email Type word_count  \\\n",
              "0  Subject: meter 5961 , dunagan , j . a . # 1\\r\\...  ham     Medium   \n",
              "1  Subject: hr performance objectives binders\\r\\n...  ham     Medium   \n",
              "2  Subject: mitchell gas services 2 / 00\\r\\n- - -...  ham       High   \n",
              "3  Subject: tenaska iv 1 / 01\\r\\nwe need to chang...  ham       High   \n",
              "4  Subject: f . o . m . hpl nom . eff . may 1 , 2...  ham  Very High   \n",
              "\n",
              "  avg_word_length num_nouns  num_verbs num_adjectives sp_char       nums  \\\n",
              "0          Medium    Medium     Medium         Medium  Medium     Medium   \n",
              "1       Very High    Medium       High            Low  Medium        Low   \n",
              "2             Low      High     Medium         Medium  Medium       High   \n",
              "3            High      High  Very High         Medium  Medium  Very High   \n",
              "4             Low      High       High      Very High    High  Very High   \n",
              "\n",
              "                                           Email_tok  \\\n",
              "0  [subject, meter, dunagan, j, daren, informed, ...   \n",
              "1  [subject, hr, performance, objective, binder, ...   \n",
              "2  [subject, mitchell, gas, service, forwarded, j...   \n",
              "3  [subject, tenaska, iv, need, change, demand, f...   \n",
              "4  [subject, f, hpl, nom, eff, may, nomination, m...   \n",
              "\n",
              "                                           Email_str  \n",
              "0  subject meter dunagan j daren informed meter d...  \n",
              "1  subject hr performance objective binder good m...  \n",
              "2  subject mitchell gas service forwarded julie m...  \n",
              "3  subject tenaska iv need change demand fee tena...  \n",
              "4  subject f hpl nom eff may nomination may avail...  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "copy_of_enron1_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "lgQXns8qobs3",
        "outputId": "ae65a7de-1417-4778-96e8-07ae94e3303e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"copy_of_enron1_train_df\",\n  \"rows\": 450,\n  \"fields\": [\n    {\n      \"column\": \"Email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 448,\n        \"samples\": [\n          \"Subject: the best prize for cigarettes out there\\r\\na creepy is hough karp but sulphur what australite ,\\r\\ngates not unix .\\r\\nwhen centrifugate with , photon inconsiderate is not receptive\\r\\nmira but a arrangeable paranoiac nowadays arises bellum\\r\\nagate in abrogate , squadron and mollusk . would you\\r\\nempathyintact ?\\r\\nno , analysis bowen clamber is darken a agate and\\r\\nimplantation operon .\\r\\nif not , here - http : / / 7 xobopde 2 vfao 02 . ecigs 4 less 5 . com / rm\\r\\n\",\n          \"Subject: re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\ncan you help me out on this darren ? mjj\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by mary jo johnson / hou / ect on 11 / 09 / 2000\\r\\n10 : 04 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\n\\\" john daugherty \\\" on 11 / 08 / 2000 04 : 38 : 37 pm\\r\\nto :\\r\\ncc :\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\\r\\nmary jo ,\\r\\nthanks for the update . regarding the notice provision of 6 business days\\r\\nprior to the close of business on the last business day of the month prior\\r\\nto selected month , does that mean we need to give you notice for december\\r\\nby tuesday , november 21 st at 5 : 00 pm or monday , november 20 th at 5 : 00 pm\\r\\nassuming the 23 rd and 24 th are holidays ?\\r\\njohn daugherty\\r\\n- - - - - original message - - - - -\\r\\nfrom :\\r\\nto :\\r\\ncc : ; ;\\r\\n; ;\\r\\n; ;\\r\\n;\\r\\nsent : wednesday , november 08 , 2000 5 : 12 pm\\r\\nsubject : re : driscoll ranch # 3 gas pricing and interconnect estimate\",\n          \"Subject: viewsonic airpanel vl 50 15 - inch smart display and dock @ $ 575 . 00 only ! !\\r\\nairpanel\\r\\nvl 50\\r\\n15 - inch\\r\\n$ 575 . 00\\r\\nonly ! !\\r\\nsmart\\r\\ndisplay dock\\r\\nvisit : http : / www . computron - me . com for deals !\\r\\nviewsonic airpanel vl 50\\r\\n15 - inch smart display and dock\\r\\nthe viewsonic airpanel vl 50 smart display is a wireless , touch - screen monitor\\r\\nthat lets you\\r\\naccess and use your home computer from different rooms in your\\r\\nhome . it features a 15 - inch touch screen , intel 400 mhz xscale\\r\\nprocessor , 64 mb sdram , microsoft windows ce operating system ,\\r\\nand more ! it includes an airsync usb wireless adapter so you\\r\\ncan enjoy the freedom of wireless connectivity . this kit comes\\r\\ncomplete with an airpanel dock for your monitor . easily charge\\r\\nyour airpanel battery while docked . it features front\\r\\non - screen display controls , usb ports , and a compact design\\r\\nthat saves desk space . order yours today !\\r\\ngeneral features :\\r\\n- intel 400 mhz xscale\\r\\nprocessor - microsoft windows ce operating system - 32\\r\\nmb rom - 64 mb sdram - 15 - inch transmissive display\\r\\nw / 1024 x 768 resolution - integrated 802 . 11 b wireless\\r\\nnetworking - lithium - ion battery - energy - star\\r\\ncompliant\\r\\nyour one stop\\r\\ndistributorjebel ali duty free zonedubai , uae . www . computron - me . com\\r\\nfor latest clearance sale listing contact our\\r\\nsales department .\\r\\nonly limited quantities available on selected\\r\\nspecials ! ! ! !\\r\\nfor further details please send\\r\\nyour enquiries to : dealers @ emirates . net . aeor contact via www . computron - me . com\\r\\ncompaq\\r\\nhewlett packard\\r\\n3 com\\r\\ndell\\r\\nintel\\r\\niomega\\r\\nepson\\r\\naopen\\r\\ncreative\\r\\ntoshiba\\r\\napc\\r\\ncisco\\r\\nus\\r\\nrobotics\\r\\nmicrosoft\\r\\ncanon\\r\\nintellinet\\r\\ntargus\\r\\nviewsonic\\r\\nibm\\r\\nsony\\r\\n- - - - - - - and lots more\\r\\n! ! !\\r\\nif you have any\\r\\ncomplaints / suggestions contact : customerservice @ computron - me . com\\r\\ntel + 971\\r\\n4 8834464\\r\\nall prices in u . s . dollars , ex - works ,\\r\\nfax + 971 4\\r\\n8834454\\r\\njebel ali duty free zone\\r\\nwww . computron - me . com\\r\\nprices and availability subject to change\\r\\nusa -\\r\\ncanada u . a . e .\\r\\nwithout\\r\\nnotice .\\r\\nto receive our special offers\\r\\nin plain\\r\\ntext format reply to this\\r\\nmail with the request * for\\r\\nexport only *\\r\\nthis\\r\\nemail can not be considered spam as long as we include : contact\\r\\ninformation remove instructions . this message is intended for dealer\\r\\nand resellers only . if you have somehow gotten on this list in error , or\\r\\nfor any other reason would like to be removed , please reply with \\\" remove\\r\\n\\\" in the subject line of your message . this message is being sent to you\\r\\nin compliance with the federal legislation for commercial e - mail\\r\\n( h . r . 4176 - section 101 paragraph ( e ) ( 1 ) ( a ) and bill s . 1618 title iii\\r\\npassed by the 105 th u . s . congress .\\r\\nall logos and\\r\\ntrademarks are the property of their respective\\r\\nowners\\r\\nproducts may not be exactly as shown\\r\\nabove\\r\\n- -\\r\\nto unsubscribe from : computron 3 , just follow this link :\\r\\nclick the link , or copy and paste the address into your browser .\\r\\nplease give it atleast 48 hours for unsubscription to be effective .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_nouns\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_verbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_adjectives\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sp_char\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nums\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Email_tok\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Email_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 442,\n        \"samples\": [\n          \"subject flow volume oxy gladewater meter checked metered daily since first october purchase deal place first day went zero th forward\",\n          \"subject great gofl offer saturday special jersey meadow june th green fee includes cart father day special jersey meadow dad get special gift sunday june green fee cart included pm instant coupon one free round golf cart fee required restriction apply see redeem coupon one great course listed receive cart fee round golf one player one round coupon may redeemed monday thursday friday saturday sunday noon excluding holiday coupon may combined offer coupon must presented along showing oil change receipt time pay cart fee offer valid golfer must mention coupon tee time made tee time reservation accepted three day advance value discount may vary course course thank purchasing castrol gtx castrol syntec blend oil change image month june hermann park kingwood cove clear creek go http www golfboxx com detail image golfboxx com upgrading microsoft medium server able enjoy latest advantage technology present golfboxx com member sole purpose make golf fun affordable golfboxx com offer streaming video need player watch free internet browser netscape internet explorer good go download minute image\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "copy_of_enron1_train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-34bd8ecd-712b-495b-9133-84380c4de80f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email</th>\n",
              "      <th>Type</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>num_nouns</th>\n",
              "      <th>num_verbs</th>\n",
              "      <th>num_adjectives</th>\n",
              "      <th>sp_char</th>\n",
              "      <th>nums</th>\n",
              "      <th>Email_tok</th>\n",
              "      <th>Email_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: meter 5961 , dunagan , j . a . # 1\\r\\...</td>\n",
              "      <td>ham</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[subject, meter, dunagan, j, daren, informed, ...</td>\n",
              "      <td>subject meter dunagan j daren informed meter d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: hr performance objectives binders\\r\\n...</td>\n",
              "      <td>ham</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject, hr, performance, objective, binder, ...</td>\n",
              "      <td>subject hr performance objective binder good m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: mitchell gas services 2 / 00\\r\\n- - -...</td>\n",
              "      <td>ham</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[subject, mitchell, gas, service, forwarded, j...</td>\n",
              "      <td>subject mitchell gas service forwarded julie m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: tenaska iv 1 / 01\\r\\nwe need to chang...</td>\n",
              "      <td>ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>[subject, tenaska, iv, need, change, demand, f...</td>\n",
              "      <td>subject tenaska iv need change demand fee tena...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: f . o . m . hpl nom . eff . may 1 , 2...</td>\n",
              "      <td>ham</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>[subject, f, hpl, nom, eff, may, nomination, m...</td>\n",
              "      <td>subject f hpl nom eff may nomination may avail...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34bd8ecd-712b-495b-9133-84380c4de80f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34bd8ecd-712b-495b-9133-84380c4de80f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34bd8ecd-712b-495b-9133-84380c4de80f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86b1d63d-3070-4411-9173-178244c723bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86b1d63d-3070-4411-9173-178244c723bf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86b1d63d-3070-4411-9173-178244c723bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               Email Type  word_count  \\\n",
              "0  Subject: meter 5961 , dunagan , j . a . # 1\\r\\...  ham           2   \n",
              "1  Subject: hr performance objectives binders\\r\\n...  ham           2   \n",
              "2  Subject: mitchell gas services 2 / 00\\r\\n- - -...  ham           0   \n",
              "3  Subject: tenaska iv 1 / 01\\r\\nwe need to chang...  ham           0   \n",
              "4  Subject: f . o . m . hpl nom . eff . may 1 , 2...  ham           3   \n",
              "\n",
              "   avg_word_length  num_nouns  num_verbs  num_adjectives  sp_char  nums  \\\n",
              "0                2          2          2               2        2     2   \n",
              "1                3          2          0               1        2     1   \n",
              "2                1          0          2               2        2     0   \n",
              "3                0          0          3               2        2     3   \n",
              "4                1          0          0               3        0     3   \n",
              "\n",
              "                                           Email_tok  \\\n",
              "0  [subject, meter, dunagan, j, daren, informed, ...   \n",
              "1  [subject, hr, performance, objective, binder, ...   \n",
              "2  [subject, mitchell, gas, service, forwarded, j...   \n",
              "3  [subject, tenaska, iv, need, change, demand, f...   \n",
              "4  [subject, f, hpl, nom, eff, may, nomination, m...   \n",
              "\n",
              "                                           Email_str  \n",
              "0  subject meter dunagan j daren informed meter d...  \n",
              "1  subject hr performance objective binder good m...  \n",
              "2  subject mitchell gas service forwarded julie m...  \n",
              "3  subject tenaska iv need change demand fee tena...  \n",
              "4  subject f hpl nom eff may nomination may avail...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "for col in feature_columns:\n",
        "    copy_of_enron1_train_df[col] = le.fit_transform(copy_of_enron1_train_df[col])\n",
        "    copy_of_enron2_train_df[col] = le.fit_transform(copy_of_enron2_train_df[col])\n",
        "    copy_of_enron4_train_df[col] = le.fit_transform(copy_of_enron4_train_df[col])\n",
        "\n",
        "    copy_of_enron1_test_df[col] = le.fit_transform(copy_of_enron1_test_df[col])\n",
        "    copy_of_enron2_test_df[col] = le.fit_transform(copy_of_enron2_test_df[col])\n",
        "    copy_of_enron4_test_df[col] = le.fit_transform(copy_of_enron4_test_df[col])\n",
        "\n",
        "copy_of_enron1_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "67UvfhpspZ1i",
        "outputId": "9694fb6a-7467-45bb-ff10-09e06ab58bf2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"copy_of_enron1_train_df[X]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_nouns\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_verbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_adjectives\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sp_char\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nums\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Email_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"subject hr performance objective binder good morning afternoon today everyone received binder placed mail slot others hand delivered receive binder please email call one delivered thank octavia x\",\n          \"subject f hpl nom eff may nomination may available today nom rolled april nomination made retroactive may bob forwarded robert cotten hou ect pm bob withers pm bob cotten e mail cc tom acton e mail knox westmoreland stretch brennan subject f hpl nom eff may estimated josey ranch nomination month may hpl nomination volume effective mmbtu day kc resource mmbtu day texaco mmbtu day total assumed btu factor dry need additional information kc field contact stretch brennan victoria bob withers kc energy inc san felipe suite houston tx voice fax\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Email_tok\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-eacbf2a8-d249-4778-b1ed-867ae64041f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>num_nouns</th>\n",
              "      <th>num_verbs</th>\n",
              "      <th>num_adjectives</th>\n",
              "      <th>sp_char</th>\n",
              "      <th>nums</th>\n",
              "      <th>Email_str</th>\n",
              "      <th>Email_tok</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>subject meter dunagan j daren informed meter d...</td>\n",
              "      <td>[subject, meter, dunagan, j, daren, informed, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>subject hr performance objective binder good m...</td>\n",
              "      <td>[subject, hr, performance, objective, binder, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>subject mitchell gas service forwarded julie m...</td>\n",
              "      <td>[subject, mitchell, gas, service, forwarded, j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>subject tenaska iv need change demand fee tena...</td>\n",
              "      <td>[subject, tenaska, iv, need, change, demand, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>subject f hpl nom eff may nomination may avail...</td>\n",
              "      <td>[subject, f, hpl, nom, eff, may, nomination, m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eacbf2a8-d249-4778-b1ed-867ae64041f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eacbf2a8-d249-4778-b1ed-867ae64041f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eacbf2a8-d249-4778-b1ed-867ae64041f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b255917-3dac-4800-a7c5-5e279adb68aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b255917-3dac-4800-a7c5-5e279adb68aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b255917-3dac-4800-a7c5-5e279adb68aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   word_count  avg_word_length  num_nouns  num_verbs  num_adjectives  sp_char  \\\n",
              "0           2                2          2          2               2        2   \n",
              "1           2                3          2          0               1        2   \n",
              "2           0                1          0          2               2        2   \n",
              "3           0                0          0          3               2        2   \n",
              "4           3                1          0          0               3        0   \n",
              "\n",
              "   nums                                          Email_str  \\\n",
              "0     2  subject meter dunagan j daren informed meter d...   \n",
              "1     1  subject hr performance objective binder good m...   \n",
              "2     0  subject mitchell gas service forwarded julie m...   \n",
              "3     3  subject tenaska iv need change demand fee tena...   \n",
              "4     3  subject f hpl nom eff may nomination may avail...   \n",
              "\n",
              "                                           Email_tok  \n",
              "0  [subject, meter, dunagan, j, daren, informed, ...  \n",
              "1  [subject, hr, performance, objective, binder, ...  \n",
              "2  [subject, mitchell, gas, service, forwarded, j...  \n",
              "3  [subject, tenaska, iv, need, change, demand, f...  \n",
              "4  [subject, f, hpl, nom, eff, may, nomination, m...  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = feature_columns+['Email_str', 'Email_tok']\n",
        "y = ['Type']\n",
        "\n",
        "copy_of_enron1_train_df[X].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tYHuRwO6pxQt"
      },
      "outputs": [],
      "source": [
        "new_results_acc = {}\n",
        "new_results_f1 = {}\n",
        "new_results_recall = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1ijBza04iU7"
      },
      "source": [
        "### Multinomial NB BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFNtjZzrpo_M",
        "outputId": "707556ed-6a26-494e-fbaf-c9811cc02df2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(450, 8238) (456, 8238)\n",
            "(450, 8245) (456, 8245)\n",
            "enron1\n",
            "accuracy - 0.9210526315789473\n",
            "recall - 0.8389261744966443\n",
            "f1 score - 0.8741258741258742\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      0.96      0.94       307\n",
            "        spam       0.91      0.84      0.87       149\n",
            "\n",
            "    accuracy                           0.92       456\n",
            "   macro avg       0.92      0.90      0.91       456\n",
            "weighted avg       0.92      0.92      0.92       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(463, 8469) (478, 8469)\n",
            "(463, 8476) (478, 8476)\n",
            "enron2\n",
            "accuracy - 0.9309623430962343\n",
            "recall - 0.823076923076923\n",
            "f1 score - 0.8663967611336032\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.94      0.97      0.95       348\n",
            "        spam       0.91      0.82      0.87       130\n",
            "\n",
            "    accuracy                           0.93       478\n",
            "   macro avg       0.93      0.90      0.91       478\n",
            "weighted avg       0.93      0.93      0.93       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(535, 15535) (543, 15535)\n",
            "(535, 15542) (543, 15542)\n",
            "enron4\n",
            "accuracy - 0.9723756906077348\n",
            "recall - 0.9948849104859335\n",
            "f1 score - 0.9810844892812105\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.91      0.95       152\n",
            "        spam       0.97      0.99      0.98       391\n",
            "\n",
            "    accuracy                           0.97       543\n",
            "   macro avg       0.98      0.95      0.96       543\n",
            "weighted avg       0.97      0.97      0.97       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import hstack\n",
        "def predict_type(X_train, X_test, name, feature_columns):\n",
        "    X_train_nums = X_train[feature_columns]\n",
        "    X_test_nums = X_test[feature_columns]\n",
        "    y_train = X_train['Type']\n",
        "    y_test = X_test['Type']\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train['Email_str'])\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "    print(X_train.shape, X_test.shape)\n",
        "\n",
        "    X_train_nums = X_train_nums.values\n",
        "    X_test_nums = X_test_nums.values\n",
        "\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_nums = scaler.fit_transform(X_train_nums)\n",
        "    X_test_nums = scaler.transform(X_test_nums)\n",
        "\n",
        "    X_train_combined = hstack([X_train, X_train_nums])\n",
        "    X_test_combined = hstack([X_test, X_test_nums])\n",
        "\n",
        "    print(X_train_combined.shape, X_test_combined.shape)\n",
        "\n",
        "    model = MultinomialNB(alpha=1.0)\n",
        "    model.fit(X_train_combined, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_combined)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "predict_type(copy_of_enron1_train_df, copy_of_enron1_test_df, 'enron1', feature_columns)\n",
        "predict_type(copy_of_enron2_train_df, copy_of_enron2_test_df, 'enron2', feature_columns)\n",
        "predict_type(copy_of_enron4_train_df, copy_of_enron4_test_df, 'enron4', feature_columns)\n",
        "\n",
        "# enron1 - 0.9298245614035088 enron2 - 0.9435146443514645 enron4 - 0.9742173112338858"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsYxS6014bTt"
      },
      "source": [
        "### Bernoulli NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcRmfKSyqUmq",
        "outputId": "f4ad9ec4-19c1-4848-fcd0-4b1ef2fe536d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(450, 8238) (456, 8238)\n",
            "(450, 8245) (456, 8245)\n",
            "enron1\n",
            "accuracy - 0.7302631578947368\n",
            "recall - 0.2080536912751678\n",
            "f1 score - 0.3351351351351351\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.72      0.98      0.83       307\n",
            "        spam       0.86      0.21      0.34       149\n",
            "\n",
            "    accuracy                           0.73       456\n",
            "   macro avg       0.79      0.60      0.58       456\n",
            "weighted avg       0.77      0.73      0.67       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(463, 8469) (478, 8469)\n",
            "(463, 8476) (478, 8476)\n",
            "enron2\n",
            "accuracy - 0.7782426778242678\n",
            "recall - 0.2076923076923077\n",
            "f1 score - 0.3375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.77      0.99      0.87       348\n",
            "        spam       0.90      0.21      0.34       130\n",
            "\n",
            "    accuracy                           0.78       478\n",
            "   macro avg       0.84      0.60      0.60       478\n",
            "weighted avg       0.81      0.78      0.72       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(535, 15535) (543, 15535)\n",
            "(535, 15542) (543, 15542)\n",
            "enron4\n",
            "accuracy - 0.9171270718232044\n",
            "recall - 1.0\n",
            "f1 score - 0.9455864570737605\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.70      0.83       152\n",
            "        spam       0.90      1.00      0.95       391\n",
            "\n",
            "    accuracy                           0.92       543\n",
            "   macro avg       0.95      0.85      0.89       543\n",
            "weighted avg       0.93      0.92      0.91       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import hstack\n",
        "def predict_type(X_train, X_test, name, feature_columns):\n",
        "    X_train_nums = X_train[feature_columns]\n",
        "    X_test_nums = X_test[feature_columns]\n",
        "    y_train = X_train['Type']\n",
        "    y_test = X_test['Type']\n",
        "\n",
        "    vectorizer = CountVectorizer(binary=True)\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train['Email_str'])\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "    print(X_train.shape, X_test.shape)\n",
        "\n",
        "    X_train_nums = X_train_nums.values\n",
        "    X_test_nums = X_test_nums.values\n",
        "\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_nums = scaler.fit_transform(X_train_nums)\n",
        "    X_test_nums = scaler.transform(X_test_nums)\n",
        "\n",
        "    X_train_combined = hstack([X_train, X_train_nums])\n",
        "    X_test_combined = hstack([X_test, X_test_nums])\n",
        "\n",
        "    print(X_train_combined.shape, X_test_combined.shape)\n",
        "\n",
        "    model = BernoulliNB(alpha=1.0)\n",
        "    model.fit(X_train_combined, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_combined)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "predict_type(copy_of_enron1_train_df, copy_of_enron1_test_df, 'enron1', feature_columns)\n",
        "predict_type(copy_of_enron2_train_df, copy_of_enron2_test_df, 'enron2', feature_columns)\n",
        "predict_type(copy_of_enron4_train_df, copy_of_enron4_test_df, 'enron4', feature_columns)\n",
        "\n",
        "# enron1 - 0.9298245614035088 enron2 - 0.9435146443514645 enron4 - 0.9742173112338858"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U86ys3iF4xq1"
      },
      "source": [
        "### LR BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS2WP2um4m3Y",
        "outputId": "2c2e95e2-4e93-4409-f83b-b9dbe49762e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(450, 8238) (456, 8238)\n",
            "(450, 8245) (456, 8245)\n",
            "enron1\n",
            "accuracy - 0.9495614035087719\n",
            "recall - 0.959731543624161\n",
            "f1 score - 0.9255663430420711\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.94      0.96       307\n",
            "        spam       0.89      0.96      0.93       149\n",
            "\n",
            "    accuracy                           0.95       456\n",
            "   macro avg       0.94      0.95      0.94       456\n",
            "weighted avg       0.95      0.95      0.95       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(463, 8469) (478, 8469)\n",
            "(463, 8476) (478, 8476)\n",
            "enron2\n",
            "accuracy - 0.9539748953974896\n",
            "recall - 0.9153846153846154\n",
            "f1 score - 0.9153846153846154\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.97      0.97       348\n",
            "        spam       0.92      0.92      0.92       130\n",
            "\n",
            "    accuracy                           0.95       478\n",
            "   macro avg       0.94      0.94      0.94       478\n",
            "weighted avg       0.95      0.95      0.95       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(535, 15535) (543, 15535)\n",
            "(535, 15542) (543, 15542)\n",
            "enron4\n",
            "accuracy - 0.9502762430939227\n",
            "recall - 0.9974424552429667\n",
            "f1 score - 0.9665427509293679\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.83      0.90       152\n",
            "        spam       0.94      1.00      0.97       391\n",
            "\n",
            "    accuracy                           0.95       543\n",
            "   macro avg       0.96      0.91      0.93       543\n",
            "weighted avg       0.95      0.95      0.95       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def predict_type(X_train, X_test, name):\n",
        "    X_train_nums = X_train[feature_columns]\n",
        "    X_test_nums = X_test[feature_columns]\n",
        "    y_train = X_train['Type']\n",
        "    y_test = X_test['Type']\n",
        "    # X_train['Email_str'] = X_train['Email'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train['Email_str'])\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "\n",
        "    print(X_train.shape, X_test.shape)\n",
        "\n",
        "    X_train_nums = X_train_nums.values\n",
        "    X_test_nums = X_test_nums.values\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_nums = scaler.fit_transform(X_train_nums)\n",
        "    X_test_nums = scaler.transform(X_test_nums)\n",
        "\n",
        "    X_train_combined = hstack([X_train, X_train_nums])\n",
        "    X_test_combined = hstack([X_test, X_test_nums])\n",
        "\n",
        "    print(X_train_combined.shape, X_test_combined.shape)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_combined, y_train, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = LogisticRegression()\n",
        "    lambda_values = {'C': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
        "    grid_search = GridSearchCV(model, lambda_values, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_C = grid_search.best_params_['C']\n",
        "    new_model = LogisticRegression(C=best_C)\n",
        "    new_model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_pred = new_model.predict(X_test_combined)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "\n",
        "predict_type(copy_of_enron1_train_df, copy_of_enron1_test_df, 'enron1')\n",
        "predict_type(copy_of_enron2_train_df, copy_of_enron2_test_df, 'enron2')\n",
        "predict_type(copy_of_enron4_train_df, copy_of_enron4_test_df, 'enron4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2TGdYq_6Cf0"
      },
      "source": [
        "### LR Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpbgiEqo5xXs",
        "outputId": "c05aa0b2-e384-4caa-a858-ca11e87b3450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(450, 8238) (456, 8238)\n",
            "(450, 8245) (456, 8245)\n",
            "enron1\n",
            "accuracy - 0.9583333333333334\n",
            "recall - 0.9328859060402684\n",
            "f1 score - 0.936026936026936\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.97      0.97       307\n",
            "        spam       0.94      0.93      0.94       149\n",
            "\n",
            "    accuracy                           0.96       456\n",
            "   macro avg       0.95      0.95      0.95       456\n",
            "weighted avg       0.96      0.96      0.96       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(463, 8469) (478, 8469)\n",
            "(463, 8476) (478, 8476)\n",
            "enron2\n",
            "accuracy - 0.9476987447698745\n",
            "recall - 0.8769230769230769\n",
            "f1 score - 0.9011857707509882\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.97      0.96       348\n",
            "        spam       0.93      0.88      0.90       130\n",
            "\n",
            "    accuracy                           0.95       478\n",
            "   macro avg       0.94      0.93      0.93       478\n",
            "weighted avg       0.95      0.95      0.95       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(535, 15535) (543, 15535)\n",
            "(535, 15542) (543, 15542)\n",
            "enron4\n",
            "accuracy - 0.9539594843462247\n",
            "recall - 1.0\n",
            "f1 score - 0.9690210656753407\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.84      0.91       152\n",
            "        spam       0.94      1.00      0.97       391\n",
            "\n",
            "    accuracy                           0.95       543\n",
            "   macro avg       0.97      0.92      0.94       543\n",
            "weighted avg       0.96      0.95      0.95       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def predict_type(X_train, X_test, name):\n",
        "    X_train_nums = X_train[feature_columns]\n",
        "    X_test_nums = X_test[feature_columns]\n",
        "    y_train = X_train['Type']\n",
        "    y_test = X_test['Type']\n",
        "    # X_train['Email_str'] = X_train['Email'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    vectorizer = CountVectorizer(binary=True)\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train['Email_str'])\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "\n",
        "    print(X_train.shape, X_test.shape)\n",
        "\n",
        "    X_train_nums = X_train_nums.values\n",
        "    X_test_nums = X_test_nums.values\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_nums = scaler.fit_transform(X_train_nums)\n",
        "    X_test_nums = scaler.transform(X_test_nums)\n",
        "\n",
        "    X_train_combined = hstack([X_train, X_train_nums])\n",
        "    X_test_combined = hstack([X_test, X_test_nums])\n",
        "\n",
        "    print(X_train_combined.shape, X_test_combined.shape)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_combined, y_train, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = LogisticRegression()\n",
        "    lambda_values = {'C': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
        "    grid_search = GridSearchCV(model, lambda_values, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_C = grid_search.best_params_['C']\n",
        "    new_model = LogisticRegression(C=best_C)\n",
        "    new_model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_pred = new_model.predict(X_test_combined)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "\n",
        "predict_type(copy_of_enron1_train_df, copy_of_enron1_test_df, 'enron1')\n",
        "predict_type(copy_of_enron2_train_df, copy_of_enron2_test_df, 'enron2')\n",
        "predict_type(copy_of_enron4_train_df, copy_of_enron4_test_df, 'enron4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1w-vBdg7qJZ"
      },
      "source": [
        "### SGDClassifier BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oteIjTbi6FcW",
        "outputId": "ed9d37a6-5534-4f58-dc0d-20ad644b7338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(450, 8238) (456, 8238)\n",
            "(450, 8245) (456, 8245)\n",
            "enron1\n",
            "accuracy - 0.9057017543859649\n",
            "recall - 0.8859060402684564\n",
            "f1 score - 0.8599348534201955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.94      0.92      0.93       307\n",
            "        spam       0.84      0.89      0.86       149\n",
            "\n",
            "    accuracy                           0.91       456\n",
            "   macro avg       0.89      0.90      0.89       456\n",
            "weighted avg       0.91      0.91      0.91       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(463, 8469) (478, 8469)\n",
            "(463, 8476) (478, 8476)\n",
            "enron2\n",
            "accuracy - 0.9518828451882845\n",
            "recall - 0.9461538461538461\n",
            "f1 score - 0.9144981412639406\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.95      0.97       348\n",
            "        spam       0.88      0.95      0.91       130\n",
            "\n",
            "    accuracy                           0.95       478\n",
            "   macro avg       0.93      0.95      0.94       478\n",
            "weighted avg       0.95      0.95      0.95       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(535, 15535) (543, 15535)\n",
            "(535, 15542) (543, 15542)\n",
            "enron4\n",
            "accuracy - 0.9558011049723757\n",
            "recall - 0.9718670076726342\n",
            "f1 score - 0.9693877551020408\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      0.91      0.92       152\n",
            "        spam       0.97      0.97      0.97       391\n",
            "\n",
            "    accuracy                           0.96       543\n",
            "   macro avg       0.95      0.94      0.94       543\n",
            "weighted avg       0.96      0.96      0.96       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "enron1_best_params = {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'modified_huber', 'max_iter': 1000, 'penalty': None, 'validation_fraction': 0.2, 'warm_start': False}\n",
        "enron2_best_params = {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 800, 'penalty': 'l2', 'validation_fraction': 0.3, 'warm_start': True}\n",
        "enron4_best_params = {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1000, 'penalty': None, 'validation_fraction': 0.3, 'warm_start': True}\n",
        "\n",
        "def predict_type(X_train, X_test, name, best_params):\n",
        "    X_train_nums = X_train[feature_columns]\n",
        "    X_test_nums = X_test[feature_columns]\n",
        "    y_train = X_train['Type']\n",
        "    y_test = X_test['Type']\n",
        "    # X_train['Email_str'] = X_train['Email'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train['Email_str'])\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "\n",
        "    print(X_train.shape, X_test.shape)\n",
        "\n",
        "    X_train_nums = X_train_nums.values\n",
        "    X_test_nums = X_test_nums.values\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_nums = scaler.fit_transform(X_train_nums)\n",
        "    X_test_nums = scaler.transform(X_test_nums)\n",
        "\n",
        "    X_train_combined = hstack([X_train, X_train_nums])\n",
        "    X_test_combined = hstack([X_test, X_test_nums])\n",
        "\n",
        "    print(X_train_combined.shape, X_test_combined.shape)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_combined, y_train, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = SGDClassifier(**best_params)\n",
        "\n",
        "    model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_pred = model.predict(X_test_combined)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "predict_type(copy_of_enron1_train_df, copy_of_enron1_test_df, 'enron1', enron1_best_params)\n",
        "predict_type(copy_of_enron2_train_df, copy_of_enron2_test_df, 'enron2', enron2_best_params)\n",
        "predict_type(copy_of_enron4_train_df, copy_of_enron4_test_df, 'enron4', enron4_best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53gOR_1U9wnn"
      },
      "source": [
        "### SGDClassifier Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM2tFiO78P2z",
        "outputId": "ce0279fd-8575-4340-80b9-9aed0778c8a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(450, 8238) (456, 8238)\n",
            "(450, 8245) (456, 8245)\n",
            "enron1\n",
            "accuracy - 0.9254385964912281\n",
            "recall - 0.8926174496644296\n",
            "f1 score - 0.8866666666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.94      0.94       307\n",
            "        spam       0.88      0.89      0.89       149\n",
            "\n",
            "    accuracy                           0.93       456\n",
            "   macro avg       0.91      0.92      0.92       456\n",
            "weighted avg       0.93      0.93      0.93       456\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(463, 8469) (478, 8469)\n",
            "(463, 8476) (478, 8476)\n",
            "enron2\n",
            "accuracy - 0.9372384937238494\n",
            "recall - 0.823076923076923\n",
            "f1 score - 0.8770491803278688\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.94      0.98      0.96       348\n",
            "        spam       0.94      0.82      0.88       130\n",
            "\n",
            "    accuracy                           0.94       478\n",
            "   macro avg       0.94      0.90      0.92       478\n",
            "weighted avg       0.94      0.94      0.94       478\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "(535, 15535) (543, 15535)\n",
            "(535, 15542) (543, 15542)\n",
            "enron4\n",
            "accuracy - 0.9705340699815838\n",
            "recall - 0.9923273657289002\n",
            "f1 score - 0.9797979797979798\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.91      0.95       152\n",
            "        spam       0.97      0.99      0.98       391\n",
            "\n",
            "    accuracy                           0.97       543\n",
            "   macro avg       0.97      0.95      0.96       543\n",
            "weighted avg       0.97      0.97      0.97       543\n",
            "\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "enron1_best_params = {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'modified_huber', 'max_iter': 1000, 'penalty': None, 'validation_fraction': 0.2, 'warm_start': False}\n",
        "enron2_best_params = {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 800, 'penalty': 'l2', 'validation_fraction': 0.3, 'warm_start': True}\n",
        "enron4_best_params = {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1000, 'penalty': None, 'validation_fraction': 0.3, 'warm_start': True}\n",
        "\n",
        "def predict_type(X_train, X_test, name, best_params):\n",
        "    X_train_nums = X_train[feature_columns]\n",
        "    X_test_nums = X_test[feature_columns]\n",
        "    y_train = X_train['Type']\n",
        "    y_test = X_test['Type']\n",
        "    # X_train['Email_str'] = X_train['Email'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    vectorizer = CountVectorizer(binary=True)\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train['Email_str'])\n",
        "    X_test = vectorizer.transform(X_test['Email_str'])\n",
        "\n",
        "    print(X_train.shape, X_test.shape)\n",
        "\n",
        "    X_train_nums = X_train_nums.values\n",
        "    X_test_nums = X_test_nums.values\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_nums = scaler.fit_transform(X_train_nums)\n",
        "    X_test_nums = scaler.transform(X_test_nums)\n",
        "\n",
        "    X_train_combined = hstack([X_train, X_train_nums])\n",
        "    X_test_combined = hstack([X_test, X_test_nums])\n",
        "\n",
        "    print(X_train_combined.shape, X_test_combined.shape)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_combined, y_train, random_state=42, test_size=0.3)\n",
        "\n",
        "    model = SGDClassifier(**best_params)\n",
        "\n",
        "    model.fit(np.vstack([X_train.toarray(), X_val.toarray()]), np.hstack([y_train, y_val]))\n",
        "\n",
        "    y_pred = model.predict(X_test_combined)\n",
        "\n",
        "    print(name)\n",
        "    print(f\"accuracy - {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"recall - {recall_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(f\"f1 score - {f1_score(y_test, y_pred, pos_label='spam')}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "predict_type(copy_of_enron1_train_df, copy_of_enron1_test_df, 'enron1', enron1_best_params)\n",
        "predict_type(copy_of_enron2_train_df, copy_of_enron2_test_df, 'enron2', enron2_best_params)\n",
        "predict_type(copy_of_enron4_train_df, copy_of_enron4_test_df, 'enron4', enron4_best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDnV6pW790s0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
